{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c66929e-4da1-4b5f-86ae-22ebabbf054e",
   "metadata": {},
   "source": [
    "**Ressources**:\n",
    "\n",
    "- [TF Tutorial](https://www.tensorflow.org/tutorials/images/data_augmentation)\n",
    "- [Image Augmentation](https://towardsdatascience.com/image-augmentation-for-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24b1ba-4a0d-4878-98ac-1500b9240a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import util\n",
    "import surf_hog_analysis\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5edc908-423d-4a03-a410-70050259e0c9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea342d82-0bc5-4925-8fd5-81143dc68f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0dcc8-7e3a-43df-a809-08f565e13b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.isolate_single_defects(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0559fd-47cf-4c61-bc1c-9cdee8ff59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = util.add_blackness_attributes(df, 'train_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184d6f2-2ce5-4a98-bcd3-2b446ba9fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e17cb-3365-46e2-835d-fd2928f12786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/train_single_defects_with_blackness.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e2295-3886-454c-8cb0-f78ac1a936be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = X.pop('ClassId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e524c-4a7b-4462-aa0c-6d9113a99ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a681050-f305-4756-b037-cf5c764ea58f",
   "metadata": {},
   "source": [
    "Since oversampling is only applied to the training data, we needed to split our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf3f2e-d57b-476a-b4a8-8c4d3e0551ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_for_class_id(y, class_id):\n",
    "    pos_of_class_id = (y == class_id)\n",
    "    indices = pos_of_class_id[pos_of_class_id].index.values\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b451eb7-5333-4ff4-be6f-a7167570ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_images = X_train.loc[util.get_indices_for_class_id(y_train, 1)]\n",
    "class2_images = X_train.loc[util.get_indices_for_class_id(y_train, 2)]\n",
    "class3_images = X_train.loc[util.get_indices_for_class_id(y_train, 3)]\n",
    "class4_images = X_train.loc[util.get_indices_for_class_id(y_train, 4)]\n",
    "\n",
    "print(f'There are {len(class1_images)} train images for ClassId 1')\n",
    "print(f'There are {len(class2_images)} train images for ClassId 2')\n",
    "print(f'There are {len(class3_images)} train images for ClassId 3')\n",
    "print(f'There are {len(class4_images)} train images for ClassId 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe271a5-a6fe-45c8-8861-3436019f7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ClassId 2 correspinds to {len(class2_images) / len(X_train)} % of train images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c90f8-9d46-4938-a90c-0a8701e7068b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612b6ab-2e67-4f37-9173-9862e88c9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily safe all images from `ClassId` 2\n",
    "path = pathlib.Path.cwd()\n",
    "try:\n",
    "    os.mkdir(path.joinpath('data','oversampling_test'))\n",
    "except:\n",
    "    print('Images already exist.')\n",
    "    \n",
    "# von Michael kopiert f√ºr Ordnererstellung basierend auf x_train\n",
    "for i in range(len(class2_images)):\n",
    "    origin_train_path = path.joinpath('data', 'train_images')\n",
    "    source_file = class2_images.iloc[i,1]\n",
    "    target_directory = path.joinpath('data', 'oversampling_test')\n",
    "    shutil.copy2(origin_train_path.joinpath(source_file) , target_directory.joinpath(source_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8208e-67f4-4cf0-95e7-38cb067c5722",
   "metadata": {},
   "source": [
    "After having a look at the images from `ClassId` 2, it becomes clear, that many of them have a high percentage of black pixels, some are entirely black even. It may be useful to delete such images since an augmentation would not really help to strengthen the robustness to identify images of this `ClassId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb5e64-295e-40cf-8c70-57c370aa8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_ids = y_train[util.get_indices_for_class_id(y_train, 2)]\n",
    "# print_batch(class2_images, class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758fb2cb-3eb8-45c2-8d01-8747e3fe56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread('data/oversampling_test/b963c168c.jpg')\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8460369-77bc-4604-9454-bf1165e3bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_black_columns(image, threshold=5):\n",
    "    num_columns = 0\n",
    "    \n",
    "    for column in range(image.shape[1]):\n",
    "        color_sum = image[:, column].sum()\n",
    "        \n",
    "        if color_sum <= image.shape[0] * 3 * threshold:\n",
    "            num_columns += 1\n",
    "            \n",
    "    return num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d997dd-1069-4def-8525-4c1428f43f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_columns = util.get_black_columns(image)\n",
    "black_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581104d-05fe-4aed-8bd9-d908fec1c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.axvline(x=black_columns)\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b64b1-f9fc-4306-95f6-56cdff9217dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_blackness_attributes(image_df, folder_extension, class_id):\n",
    "    black_columns = []\n",
    "    black_columns_percentage = []\n",
    "\n",
    "    for image_id in image_df.ImageId:\n",
    "        image = io.imread('data/' + folder_extension + '/' + image_id)\n",
    "        black_columns.append(get_black_columns(image))\n",
    "        black_columns_percentage.append(get_black_columns(image) / image.shape[1])\n",
    "\n",
    "    temp = pd.DataFrame(list(zip(black_columns, black_columns_percentage)), \n",
    "                        index=get_indices_for_class_id(y_train, class_id), \n",
    "                        columns = ['BlackColumns', 'PercentageBlack'])\n",
    "    image_df = pd.merge(image_df, temp, left_index=True, right_index=True)\n",
    "    #print(image_df)\n",
    "\n",
    "    return image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f188295-a3ca-41ff-8071-aec0e84ce032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class2_images = util.add_blackness_attributes_for_single_class(class2_images, y_train,'oversampling_test', class_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856289d-5d3b-4bc9-9a67-dab1bc1340a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2_images.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753f7ca-e871-455e-84b0-b8acc5cf72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mostly_black = class2_images.query('PercentageBlack >= 0.5').ImageId.count()\n",
    "print(f'There are {num_mostly_black} pictures (or {num_mostly_black / class2_images.shape[0]} % \\\n",
    "        of total) images that are mostly black (>= 50 %).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8a85b-f9de-4996-a8b4-0480256b15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostly_black = class2_images.query('PercentageBlack >= 0.5')\n",
    "mostly_black.PercentageBlack.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2c349b-363b-4225-8ed8-45a5083d7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostly_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8c78d-e534-45c3-873e-679ecdab5222",
   "metadata": {},
   "source": [
    "It is striking, that `mostly_black` images have at least 72 % blackness on them (up to 94.5 %)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb37eb-997e-4155-b76b-7ecd9852f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch(df_with_filepath, class_ids, blackness=False, show_keypoints=False, number_images=5):\n",
    "    # create random index for `number_images`\n",
    "    random_index = np.array(np.random.rand(2 * number_images) * len(df_with_filepath.ImageId), dtype='int')\n",
    "    print(random_index)\n",
    "    # define subplot grid\n",
    "    fig, axes = plt.subplots(number_images, 2, figsize=(18,8))\n",
    "\n",
    "    for i in range(number_images * 2):\n",
    "        # gather required info to retrieve image and label the plots\n",
    "        file_path_to_image = df_with_filepath['FilePath'].iloc[random_index[i]]\n",
    "        class_id = class_ids.iloc[random_index[i]]\n",
    "        image_id = df_with_filepath['ImageId'].iloc[random_index[i]]\n",
    "        if blackness:\n",
    "            blackness = df_with_filepath['PercentageBlack'].iloc[random_index[i]]\n",
    "        if show_keypoints:\n",
    "            keypoints = df_with_filepath['NumberKP'].iloc[random_index[i]]\n",
    "\n",
    "        # read-in the image\n",
    "        img = io.imread(file_path_to_image)\n",
    "        \n",
    "        row = i % number_images\n",
    "        col = int(i // number_images)\n",
    "        ax_ = axes[row][col]\n",
    "        ax_.imshow(img)\n",
    "        #plt.imshow(img)\n",
    "        \n",
    "        title = f'Image ID: {image_id} | ClassId: {class_id}'\n",
    "        if blackness:\n",
    "            title += f' | Percentage Black: {blackness}'\n",
    "        if show_keypoints:\n",
    "            title += f' | Number Keypoints: {keypoints}'\n",
    "        ax_.set_title(title, fontsize=14);\n",
    "        \n",
    "        # adjust distance between subplots\n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=1, \n",
    "                    top=1.2, \n",
    "                    wspace=0.2, \n",
    "                    hspace=0.2)\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e1e26-4b39-456b-8d68-bb6f620f0123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some images of `mostly_black`\n",
    "class_ids_mb = y_train[util.get_indices_for_class_id(y_train, 2)]\n",
    "print_batch(mostly_black, class_ids_mb, blackness=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae81021-ed8e-48d0-ad74-534bab1637ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_image = io.imread('data/oversampling_test/08193cfc8.jpg')\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.imshow(black_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c7eeb1-ae39-4c2f-b23f-930ac0493f13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Analysis of black percentage per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a118c-c4c2-4f23-9565-69f471892bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_images = util.add_blackness_attributes_for_single_class(class1_images, y_train, 'train_images', 1)\n",
    "class3_images = util.add_blackness_attributes_for_single_class(class3_images, y_train, 'train_images', 3)\n",
    "class4_images = util.add_blackness_attributes_for_single_class(class4_images, y_train, 'train_images', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121be072-f94d-4efc-9671-efb354835fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_images.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19364c7-c33a-48ef-9c17-833b4c93005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class3_images.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8bcc61-0ad2-486d-8041-9a7abf9dc6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class4_images.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b949dc6-a252-4dde-a2ce-1ab3fe7e689d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Augementation trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e06f3-11f3-4601-9bc5-9a1cd38cdaee",
   "metadata": {},
   "source": [
    "[`tf.image`](https://www.tensorflow.org/api_docs/python/tf/image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1523f7b7-5850-474e-9533-a17357fa25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import albumentations\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "\n",
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import data_preparation_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75babed1-692d-4b03-9fce-82c4baa1a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder():\n",
    "    # prepare folder structure\n",
    "    try:\n",
    "        path = os.getcwd()\n",
    "        temp_path = path + \"/data/augmentations\"\n",
    "        os.mkdir(temp_path)\n",
    "    except:\n",
    "        print('Folder already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0083d-60a2-4fc3-ae85-97e97c21adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "augment = A.Compose([\n",
    "    #A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # A.OneOf([\n",
    "    #     A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
    "    #     A.GridDistortion(p=0.5),\n",
    "    #     A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)                  \n",
    "    #     ], p=0.8),\n",
    "    A.CLAHE(p=0.8),\n",
    "    A.RandomBrightnessContrast(p=0.8),    \n",
    "    A.RandomGamma(p=0.8)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9334e17-8d39-452b-a4e4-15f16589a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augement_images(image_ids, num_augmentations, class_id):\n",
    "    print(f'beginning augmentation for ClassId {class_id}...')\n",
    "    start = time.time()\n",
    "    \n",
    "    path = os.getcwd()\n",
    "    #path_suffix = 'c' + str(class_id) + '/'\n",
    "    \n",
    "    target_directory_image = '/data/augmentations/'\n",
    "    \n",
    "    aug_ids = []\n",
    "    class_ids = []\n",
    "    file_paths = []\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    while i <= num_augmentations:\n",
    "        #print(i)\n",
    "        number = random.randint(0, len(image_ids) -1)\n",
    "        image_id = image_ids[number]\n",
    "        #print(image_id, mask_id)\n",
    "        \n",
    "        aug_ids.append('aug_' + str(i) + '_' + image_id)\n",
    "        class_ids.append(class_id)\n",
    "        file_paths.append(path + target_directory_image + image_id)\n",
    "        \n",
    "        original_image = cv2.imread('data/train_images/' + image_id)\n",
    "        #print(original_image)\n",
    "      \n",
    "        augmented = augment(image=original_image)\n",
    "        transformed_image = augmented['image']\n",
    "        #transformed_mask = augmented['mask']\n",
    "        \n",
    "        os.chdir(path + target_directory_image)\n",
    "        written = cv2.imwrite('aug_' + str(i) + '_' + image_id, transformed_image)\n",
    "        #print('image written:',written')\n",
    "\n",
    "        os.chdir(path)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    temp = pd.DataFrame(list(zip(file_paths,aug_ids, class_ids)), columns=['FilePath','ImageId','ClassId'])\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'augmented {num_augmentations} images of ClassId {class_id}')\n",
    "    print('time required for augmentation:', end - start)\n",
    "    print()\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7240b002-bbfa-46b6-9f68-1d5b636a2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_single_defects_with_blackness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99ea76-1b44-4277-86f2-c201b16f8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2978101-a844-4924-a748-2dad24a6a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_aug(df):\n",
    "    \n",
    "    make_folder()\n",
    "    \n",
    "    num_images_class_3 = df.groupby('ClassId').count().ImageId[3]\n",
    "    max_images = num_images_class_3\n",
    "\n",
    "    # create empty df\n",
    "    df_aug = pd.DataFrame(columns=['FilePath','ImageId','ClassId'])\n",
    "\n",
    "    for i in [1,2,3,4]:\n",
    "        image_ids = df.query('ClassId == @i').ImageId.values\n",
    "\n",
    "        temp = augement_images(image_ids=image_ids, num_augmentations=max_images, class_id=i)\n",
    "        df_aug=pd.concat([df_aug, temp], axis=0)\n",
    "\n",
    "    return df_aug.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6d362-c428-45b6-9b36-6685cd3b1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = create_df_aug(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a488e8-9550-4cc1-b8d6-5cbda291c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd5df6-e15b-454e-a67e-163876e772df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug.to_csv('data/train_single_defects_augmented.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01b631-d112-4955-b9b2-118f1b9d522b",
   "metadata": {},
   "source": [
    "#### Write Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108d830-ec8e-49c4-967a-a52f946b101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate and see the pictures and labels\n",
    "# img_batch, labels = next(it)\n",
    "# image = img_batch[0]\n",
    "# #print(img_batch)\n",
    "# plt.imshow(image)\n",
    "# print(labels[0])\n",
    "# image = image.numpy() \n",
    "# image *= 256\n",
    "# written = cv2.imwrite(cwd.as_posix() + '/image.jpg', image)\n",
    "# print(written)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
