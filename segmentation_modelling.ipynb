{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ce3b08-13a1-48e4-85d2-eab81a64acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import data_preparation_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc85831-f936-4f01-aee0-bf8aedf9c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(class_id, size_x, size_y):\n",
    "    images = []\n",
    "    path_suffix = 'c' + str(class_id) + '/'\n",
    "\n",
    "    for directory_path in glob.glob('data/segmentation/test/' + path_suffix):\n",
    "        for img_path in sorted(glob.glob(os.path.join(directory_path, \"*.jpg\"))):\n",
    "            #print(img_path)\n",
    "            #break\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "            img = cv2.resize(img, (size_y, size_x))\n",
    "            img = img/255\n",
    "            #print(img)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            images.append(img)\n",
    "            #train_labels.append(label)\n",
    "    #Convert list to array for machine learning processing        \n",
    "    images = np.array(images)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ff423c-6843-4c99-ad93-e6b8b771a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_images(1,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c70b871-a8ef-4ff3-b0d9-32b0ea55fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(class_id, size_x, size_y):\n",
    "    images = []\n",
    "    path_suffix = 'c' + str(class_id) + '/'\n",
    "\n",
    "    for directory_path in glob.glob('data/segmentation/test_mask/' + path_suffix):\n",
    "        for img_path in sorted(glob.glob(os.path.join(directory_path, \"*.jpg\"))):\n",
    "            #print(img_path)\n",
    "            #break\n",
    "            img = cv2.imread(img_path, 0)       \n",
    "            img = cv2.resize(img, (size_y, size_x))\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            images.append(img)\n",
    "            #train_labels.append(label)\n",
    "    #Convert list to array for machine learning processing        \n",
    "    images = np.array(images)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c338a437-c203-4427-a55f-23319c7963dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_variables(class_id, train_images, train_masks, size_x, size_y):\n",
    "    # get preprocessing for `EfficientNetB5`\n",
    "    preprocess_input = sm.get_preprocessing('efficientnetb5')\n",
    "    \n",
    "    # prepare variables\n",
    "    x_train = preprocess_input(train_images)\n",
    "    y_train = np.expand_dims(train_masks, axis=3)\n",
    "    # y_train = y_train/255\n",
    "\n",
    "    x_val = get_images(class_id=class_id, size_x=size_x, size_y=size_y)\n",
    "    x_val = preprocess_input(x_val)\n",
    "    y_val = get_masks(class_id=class_id, size_x=size_x, size_y=size_y)\n",
    "    y_val = np.expand_dims(y_val, axis=3) #May not be necessary.. leftover from previous code \n",
    "    # y_val = y_val / 255\n",
    "\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c9d0e7-4435-4712-85ca-26940c173290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compiled_model(size_x, size_y, metric_for_model):\n",
    "    # set the correct framework for the model to work\n",
    "    sm.set_framework('tf.keras')\n",
    "    sm.framework()\n",
    "    \n",
    "    # define model\n",
    "    model = sm.Unet('efficientnetb5',\n",
    "                    #input_shape=(size_x, size_y, 3),\n",
    "                    classes=1,\n",
    "                    activation='sigmoid',\n",
    "                    encoder_weights='imagenet',\n",
    "                    encoder_freeze=True\n",
    "                   )\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[metric_for_model])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f902159-d93b-4867-9029-cccc348d0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history_from_mask_model(class_id, size_x, size_y, metric_for_model):\n",
    "    # load images and masks as input for model\n",
    "    train_images, train_masks = data_preparation_cnn.get_resized_image_and_mask_lists(class_id=class_id, \n",
    "                                                                              size_x=size_x, \n",
    "                                                                              size_y=size_y)\n",
    "\n",
    "    # build input variables for model\n",
    "    x_train, y_train, x_val, y_val = prepare_input_variables(class_id, \n",
    "                                                             train_images, \n",
    "                                                             train_masks, \n",
    "                                                             size_x, \n",
    "                                                             size_y)\n",
    "        \n",
    "    # create a compiled model\n",
    "    model = build_compiled_model(size_x, size_y, metric_for_model)\n",
    "    \n",
    "    print(f'beginning training with masks')\n",
    "    # fit the model\n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        batch_size=32, \n",
    "                        epochs=3,\n",
    "                        verbose=True,\n",
    "                        validation_data=(x_val, y_val)\n",
    "                       )\n",
    "    \n",
    "    # save model\n",
    "    model_name = 'models/class' + str(class_id) + '_mask_generator.h5'\n",
    "    model.save(model_name)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d122feb2-1311-43ad-88ba-6940cc007c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mask_generating_models(size_x, size_y, metric_for_model):\n",
    "    \n",
    "    losses = []\n",
    "    losses_val = []\n",
    "    \n",
    "    metric_results = []\n",
    "    metric_results_val = []\n",
    "    \n",
    "    for class_id in [1,2,3,4]:\n",
    "        print(f'building model for defect class {class_id}...')\n",
    "        \n",
    "        # extract the history for each model\n",
    "        history = get_history_from_mask_model(class_id, size_x, size_y, metric_for_model)\n",
    "        \n",
    "        losses.append(history.history['loss'])\n",
    "        losses_val.append(history.history['val_loss'])\n",
    "        \n",
    "        metric_results = history.history[metric_for_model]\n",
    "        metric_results_val = history.history['val_' + metric_for_model]\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('model successfully generated and saved to file!')\n",
    "        print('-----'*10)\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dc9287b-1498-4282-aea5-13dc6df98e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PARAMETERS\n",
    "SIZE_X = 128\n",
    "SIZE_Y = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90bde60b-ef2b-4cad-8334-7c4ee771b76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model for defect class 1...\n",
      "beginning training with masks\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 13:36:59.488194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 13:39:41.189111: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 182s 5s/step - loss: 0.2409 - accuracy: 0.9648 - val_loss: 0.3345 - val_accuracy: 0.9863\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - 186s 6s/step - loss: 0.0720 - accuracy: 0.9898 - val_loss: 0.2027 - val_accuracy: 0.9887\n",
      "Epoch 3/3\n",
      "32/32 [==============================] - 246s 8s/step - loss: 0.0511 - accuracy: 0.9899 - val_loss: 0.0887 - val_accuracy: 0.9887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabioteichmann/neuefische/projects/CapstoneProject_SteelDefectDetection/.venv/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model successfully generated and saved to file!\n",
      "--------------------------------------------------\n",
      "\n",
      "building model for defect class 2...\n",
      "beginning training with masks\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 13:47:24.556497: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 13:52:14.946583: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 310s 9s/step - loss: 0.2235 - accuracy: 0.9717 - val_loss: 0.4122 - val_accuracy: 0.9229\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - 227s 7s/step - loss: 0.0615 - accuracy: 0.9917 - val_loss: 0.2309 - val_accuracy: 0.9917\n",
      "Epoch 3/3\n",
      "32/32 [==============================] - 285s 9s/step - loss: 0.0396 - accuracy: 0.9917 - val_loss: 0.0939 - val_accuracy: 0.9917\n",
      "model successfully generated and saved to file!\n",
      "--------------------------------------------------\n",
      "\n",
      "building model for defect class 3...\n",
      "beginning training with masks\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 14:01:31.185015: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.9169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 14:07:01.196614: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 392s 11s/step - loss: 0.2993 - accuracy: 0.9169 - val_loss: 2.3192 - val_accuracy: 0.0917\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - 374s 12s/step - loss: 0.1749 - accuracy: 0.9438 - val_loss: 0.4077 - val_accuracy: 0.8349\n",
      "Epoch 3/3\n",
      "32/32 [==============================] - 341s 11s/step - loss: 0.1607 - accuracy: 0.9465 - val_loss: 0.6348 - val_accuracy: 0.7412\n",
      "model successfully generated and saved to file!\n",
      "--------------------------------------------------\n",
      "\n",
      "building model for defect class 4...\n",
      "beginning training with masks\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 14:20:13.138747: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.9166 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 14:26:08.107168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 381s 11s/step - loss: 0.2813 - accuracy: 0.9166 - val_loss: 4.7091 - val_accuracy: 0.5601\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - 280s 9s/step - loss: 0.1467 - accuracy: 0.9484 - val_loss: 1.5033 - val_accuracy: 0.6028\n",
      "Epoch 3/3\n",
      "32/32 [==============================] - 259s 8s/step - loss: 0.1234 - accuracy: 0.9542 - val_loss: 0.3237 - val_accuracy: 0.9163\n",
      "model successfully generated and saved to file!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_mask_generating_models(SIZE_X, SIZE_Y, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27566d0c-5932-4bc0-aa2e-a8a2b4c55830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true,y_pred):\n",
    "    y_true_f=tf.reshape(tf.dtypes.cast(y_true, tf.float32),[-1])\n",
    "    y_pred_f=tf.reshape(tf.dtypes.cast(y_pred, tf.float32),[-1])\n",
    "    intersection=tf.reduce_sum(y_true_f*y_pred_f)\n",
    "    return (2. * intersection + 1.) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + 1.)\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    return (1-dice_coefficient(y_true, y_pred))\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    return binary_crossentropy(y_true, y_pred) + (1-dice_coef(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
