{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2dc0b3-328b-433d-8342-611f337fee2e",
   "metadata": {},
   "source": [
    "## SURF (Speeded-Up Robust Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0408ce75-c26f-4056-8306-8688fb7acf54",
   "metadata": {},
   "source": [
    "### Import resources and display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d0dd8-73e5-4c01-8e00-78ef919af1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7073b-ca92-4639-acc0-db40733b4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b507a047-3555-413b-9a77-2cd973232ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from skimage import io\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9cba6b-c120-421a-9e7d-ee27d33b119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import util\n",
    "import surf_handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf679ea-ad5f-4529-98af-2139d5a700a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image1 = cv2.imread('data/train_images/0002cc93b.jpg')\n",
    "\n",
    "# Convert the training image to RGB\n",
    "training_image = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert the training image to gray scale\n",
    "training_gray = cv2.cvtColor(training_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Create test image by adding Scale Invariance and Rotational Invariance\n",
    "test_image = cv2.pyrDown(training_image)\n",
    "test_image = cv2.pyrDown(test_image)\n",
    "num_rows, num_cols = test_image.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), 30, 1)\n",
    "test_image = cv2.warpAffine(test_image, rotation_matrix, (num_cols, num_rows))\n",
    "\n",
    "test_gray = cv2.cvtColor(test_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Display traning image and testing image\n",
    "fx, plots = plt.subplots(2, 1, figsize=(20,10))\n",
    "\n",
    "plots[0].set_title(\"Training Image\")\n",
    "plots[0].imshow(training_image)\n",
    "\n",
    "plots[1].set_title(\"Testing Image\")\n",
    "plots[1].imshow(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cde0f2-d474-40f2-a9fa-b539d4268d2f",
   "metadata": {},
   "source": [
    "### Detect keypoints and Create Descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf38ce-9a17-4ecb-9b61-fad4f6c69ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = cv2.xfeatures2d.SURF_create(400)\n",
    "\n",
    "train_keypoints, train_descriptor = surf.detectAndCompute(training_gray, None)\n",
    "test_keypoints, test_descriptor = surf.detectAndCompute(test_gray, None)\n",
    "\n",
    "keypoints_without_size = np.copy(training_image)\n",
    "keypoints_with_size = np.copy(training_image)\n",
    "\n",
    "cv2.drawKeypoints(training_image, train_keypoints, keypoints_without_size, color = (0, 255, 0))\n",
    "\n",
    "cv2.drawKeypoints(training_image, train_keypoints, keypoints_with_size, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display image with and without keypoints size\n",
    "fx, plots = plt.subplots(2, 1, figsize=(20,10))\n",
    "\n",
    "plots[0].set_title(\"Train keypoints With Size\")\n",
    "plots[0].imshow(keypoints_with_size, cmap='gray')\n",
    "\n",
    "plots[1].set_title(\"Train keypoints Without Size\")\n",
    "plots[1].imshow(keypoints_without_size, cmap='gray')\n",
    "\n",
    "# Print the number of keypoints detected in the training image\n",
    "print(\"Number of Keypoints Detected In The Training Image: \", len(train_keypoints))\n",
    "\n",
    "# Print the number of keypoints detected in the query image\n",
    "print(\"Number of Keypoints Detected In The Query Image: \", len(test_keypoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d661c63b-0496-4f1e-938d-844c7af409dd",
   "metadata": {},
   "source": [
    "### Matching Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83cfa0-8494-4259-9d26-65073edc583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Brute Force Matcher object.\n",
    "bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck = False)\n",
    "\n",
    "# Perform the matching between the SURF descriptors of the training image and the test image\n",
    "matches = bf.match(train_descriptor, test_descriptor)\n",
    "\n",
    "# The matches with shorter distance are the ones we want.\n",
    "matches = sorted(matches, key = lambda x : x.distance)\n",
    "\n",
    "result = cv2.drawMatches(training_image, train_keypoints, test_gray, test_keypoints, matches, test_gray, flags = 2)\n",
    "\n",
    "# Display the best matching points\n",
    "plt.rcParams['figure.figsize'] = [14.0, 7.0]\n",
    "plt.title('Best Matching Points')\n",
    "plt.imshow(result)\n",
    "plt.show()\n",
    "\n",
    "# Print total number of matching points between the training and query images\n",
    "print(\"\\nNumber of Matching Keypoints Between The Training and Query Images: \", len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d1839-14f5-45ed-96de-3c7a4d19144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d23da2-5cf1-46e3-a197-1fc92e54ebf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3a923-abe6-4196-bef1-9a2321ca1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/train_images/0002cc93b.jpg',0)\n",
    "# Create SURF object. You can specify params here or later.\n",
    "# Here I set Hessian Threshold to 400\n",
    "surf = cv2.xfeatures2d.SURF_create(400)\n",
    "# Find keypoints and descriptors directly\n",
    "kp, des = surf.detectAndCompute(img,None)\n",
    "len(kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30632107-0e9f-42ab-bfcd-f5e344eb863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check present Hessian threshold\n",
    "print( surf.getHessianThreshold() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c02052-2451-4067-be16-9180a32cfc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set it to some 50000. Remember, it is just for representing in picture.\n",
    "# In actual cases, it is better to have a value 300-500\n",
    "surf.setHessianThreshold(300)\n",
    "# Again compute keypoints and check its number.\n",
    "kp, des = surf.detectAndCompute(img,None)\n",
    "print( len(kp) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569140da-f08d-4800-bf1e-cd96ae02b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.drawKeypoints(img,kp,None,(255,0,0),4)\n",
    "plt.imshow(img2),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222b510-9ab9-4192-9de1-300a64f1e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find size of descriptor\n",
    "print( surf.descriptorSize() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328f115-3ec7-4679-8035-e3e771541264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That means flag, \"extended\" is False.\n",
    "surf.getExtended()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2028cb-cdb1-41e0-a7b9-afd92bab97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we make it to True to get 128-dim descriptors.\n",
    "surf.setExtended(True)\n",
    "kp, des = surf.detectAndCompute(img,None)\n",
    "print( surf.descriptorSize() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd84e090-2318-48f3-9976-6c98441713fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( des.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b25ec-943f-46d2-a788-61af417f2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.drawKeypoints(img,kp,None,(255,0,0),4)\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0b390-a421-4443-934b-5b68a0ba1142",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### SURF-Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1cbd0-35f8-4346-9eb6-0acadbaaf65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Keypoint at:', kp[0].pt)\n",
    "print('Keypoint diameter:', kp[0].size)\n",
    "print('Direction of gradient:', kp[0].angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434d139-e774-45f7-8222-7cf0c663ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aad9b7-6752-4e8e-8dd5-9b8e59f9e81d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Apply SURF to all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b44da90-ca5d-4850-aec4-ed36d1cb84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Processing time: ~3 minutes and 40 seconds.\n",
    "\"\"\"\n",
    "\n",
    "# get current working directory\n",
    "cwd = pathlib.Path.cwd()\n",
    "train_data_dir = cwd.joinpath('data', 'train_images')\n",
    "train_images = list(train_data_dir.glob('*.jpg'))\n",
    "\n",
    "# Create SURF object. You can specify params here or later.\n",
    "# Here I set Hessian Threshold to 400\n",
    "surf = cv2.xfeatures2d.SURF_create(400)\n",
    "\n",
    "# prepare dictionary to gather data\n",
    "surf_images = {'keypoints': [],\n",
    "               'ImageId': [],\n",
    "               'NumberKP': []\n",
    "              }\n",
    "\n",
    "print('processing images...')\n",
    "start = time.time()\n",
    "\n",
    "for idx, image in enumerate(train_images):\n",
    "    surf_images['ImageId'].append(image.name)\n",
    "    \n",
    "    # `image` so far holds just the path to the image. Convert to image file\n",
    "    image = io.imread(\"data/train_images/\"+image.name)\n",
    "    # Find keypoints and descriptors directly\n",
    "    kp, des = surf.detectAndCompute(image, None)\n",
    "    \n",
    "    surf_images['keypoints'].append(kp)\n",
    "    surf_images['NumberKP'].append(len(kp))\n",
    "    if idx % 500 == 0 and idx != 0:\n",
    "        print(f'image number {idx} processed...')\n",
    "\n",
    "end = time.time()\n",
    "print('processing done.')\n",
    "print('required time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0630b-15e0-4ec5-9ee7-c0fff1ce3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame.from_dict(surf_images)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3119f4e-190c-40b6-97ad-209d054ad898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have {temp.query('NumberKP < 50').count()[0]} keypoint vectors with less than 50 keypoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c698f-f945-488f-921e-b75a156d965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.sort_values(by='NumberKP', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acecc5d-5c3c-4ece-8ac0-fc7e55d98e18",
   "metadata": {},
   "source": [
    "Adjust data frame and eliminate images that have more than 1 defect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba53bb7-62b2-467e-9d18-0072faee8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.isolate_single_defects(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbc5a2-6d27-45b2-97ff-48f477691aa9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Prepare data frame with (max) TOP50 Keypoints per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09994c13-2ac5-41cd-895a-31c5e4b1cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Expected run-time: ~ 35 minutes\n",
    "\"\"\"\n",
    "# apply functions to data frame\n",
    "temp = surf_handling.add_keypoint_parameters(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efe97b9-6a25-45b1-a0ae-01527da35888",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Save data frame for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79db137-e2b6-426a-a515-fc6c510c3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv('data/train_surf.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15d6af-ff8d-4d1f-bf43-93c7d7307573",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5846ab-0e19-4400-bed1-d192fd90ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(columns = ['x'])\n",
    "y = pd.DataFrame(columns = ['y'])\n",
    "s = pd.DataFrame(columns = ['s'])\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "start = time.time()\n",
    "x.x = temp.keypoints.apply(lambda x: get_keypoint_x(x, 1))\n",
    "end = time.time()\n",
    "print('processing time x:', end-start)\n",
    "total_time += end - start\n",
    "\n",
    "start = time.time()\n",
    "y.y = temp.keypoints.apply(lambda x: get_keypoint_y(x, 1))\n",
    "end = time.time()\n",
    "print('processing time y:', end-start)\n",
    "total_time += end - start\n",
    "\n",
    "start = time.time()\n",
    "s.s = temp.keypoints.apply(lambda x: get_keypoint_size(x, 1))\n",
    "end = time.time()\n",
    "print('processing time s:', end-start)\n",
    "total_time += end - start\n",
    "\n",
    "start = time.time()\n",
    "temp = pd.concat([temp, x, y, s], axis=1, ignore_index=False)\n",
    "\n",
    "end = time.time()\n",
    "print('processing time concat:', end-start)\n",
    "total_time += end - start\n",
    "print('total processing time was:', total_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
