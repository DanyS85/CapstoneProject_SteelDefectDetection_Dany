{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5afd02-1b30-425d-93d0-b88273c055ce",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network - Multi Classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2413f36-dd89-49dc-863d-3a649c3c9ce4",
   "metadata": {},
   "source": [
    "\n",
    "#### Intro to binary CNN\n",
    "https://towardsdatascience.com/10-minutes-to-building-a-cnn-binary-image-classifier-in-tensorflow-4e216b2034aa\n",
    "\n",
    "#### Code inspiration from here..\n",
    "\n",
    "https://medium.com/techiepedia/binary-image-classifier-cnn-using-tensorflow-a3f5d6746697 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569336d3-cf7f-419a-85d5-10378c2fefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries that might be installed beforehand\n",
    "\n",
    "#!pip install opencv-python\n",
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c414e0-0149-483d-b346-1943ab6b5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# CNN Envrionment\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Miscellaneous\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "# Python Scripts\n",
    "import sys  \n",
    "sys.path.insert(0, './Python_Scripts')\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47589bfa-f683-4bdb-b537-9921f1487387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Tensorflow version\n",
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e9033-3b8d-4b02-8dcf-087a693c377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('Data/train_complete.csv')\n",
    "df.head(2)\n",
    "\n",
    "util.isolate_single_defects(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20025832-82b1-4522-bc01-2eaa3a1fd0c4",
   "metadata": {},
   "source": [
    "## Convert from RGB to Gray-Scale:\n",
    "\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/image/rgb_to_grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c83f3-31d2-4970-af09-f9302aeb137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grey-Scaling\n",
    "original =  plt.imread('./Data/train_images/' + str(df.ImageId[0]))\n",
    "\n",
    "converted = tf.image.rgb_to_grayscale(original)\n",
    "\n",
    "print(original.shape)\n",
    "print(converted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488238a4-96e6-43f3-9682-e46fe1e0b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure as subplots\n",
    "fig, ax = plt.subplots(2, 1, constrained_layout=True, figsize=(25, 10))\n",
    "\n",
    "# Subplot 1\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(original)\n",
    "plt.xlim(0,1600)\n",
    "plt.ylim(0,256)\n",
    "ax[0].set_title('Original', fontsize= 24)\n",
    "\n",
    "\n",
    "# Subplot 2\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(converted)\n",
    "plt.xlim(0,1600) \n",
    "plt.ylim(0,256)\n",
    "ax[1].set_title('Grey-Scaled', fontsize= 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f8340-636a-4e92-9ad0-fcd10b8e50d1",
   "metadata": {},
   "source": [
    "## Test Split and Data Storage Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779f9a5-98e2-4d4c-a227-deab76aaa9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Do the test split\n",
    "#index = df.ClassId == 3 \n",
    "#df = df[index] \n",
    "df_red = df.query('Defect == 1')\n",
    "\n",
    "X = df_red.iloc[:,0:4]\n",
    "y = df_red.iloc[:,2]\n",
    "y = y - 1\n",
    "#df_red.loc[df['ClassId'] == 3,'ClassId'] = 0\n",
    "#df_red.loc[df['ClassId'] == 1,'ClassId'] = 1\n",
    "#df_red.loc[df['ClassId'] == 1,'ClassId'] = 1\n",
    "#df_red.loc[df['ClassId'] == 4,'ClassId'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da5164-b240-49bf-a343-a882670928ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d472a-db03-4e64-a612-b893ba308680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155c790-3799-4dd3-8c24-cf3156dcc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state = 42)\n",
    "length_train = len(y_train)\n",
    "length_test = len(y_test)\n",
    "print('Length of Train-Set: ' + str(len(y_train)))\n",
    "print('Length of Test-Set: ' + str(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f3ae9-8e71-4c00-a669-24ea75ac2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check No-Defect Distributions\n",
    "print('No-Defect-Ratio in Train: ' + str(round((y_train == 1).astype(int).sum(axis=0) / len(y_train),4)))\n",
    "print('No-Defect-Ratio in Test: ' + str(round((y_test == 1).astype(int).sum(axis=0) / len(y_test),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0eb3f-8799-4093-983e-085fd693cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvertToGrayScale\n",
    "def ConvertToGrayScale(file_name, input_path, target_path):\n",
    "    #original =  plt.imread(input_path + file_name)\n",
    "    original = tf.keras.utils.load_img(input_path + file_name, grayscale=False, color_mode='rgb', target_size=None)\n",
    "    converted = tf.image.rgb_to_grayscale(original)\n",
    "    tf.keras.utils.save_img(target_path + file_name, converted, data_format=None, file_format=None, scale=True)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806bdb36-d230-4eb5-a16e-49fb753cc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excute ConvertToGrayScale Function\n",
    "#input_path = './Data/train_images/'\n",
    "#target_path = './Data/train_images_GrayScaled/'\n",
    "#for i in range(len(df.ImageId)):\n",
    "#    file_name = df.ImageId[i]\n",
    "#    ConvertToGrayScale(file_name, input_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d821e-a997-4ccb-b61f-afd9b29c652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temp path for the train & test split\n",
    "def MakePathStructure():\n",
    "    path = os.getcwd()\n",
    "    \n",
    "    ## You might need to adjust the path to your local environment\n",
    "    temp_path = path + \"/Data/Temp\"\n",
    "    \n",
    "    # Make DirectoryTemp and Sub-Directories Train & Test\n",
    "    try:\n",
    "        #os.mkdir(temp_path)\n",
    "        os.mkdir(temp_path + '/Train')\n",
    "        os.mkdir(temp_path + '/Test')\n",
    "        os.mkdir(temp_path + '/Train/C1')\n",
    "        os.mkdir(temp_path + '/Train/C2')\n",
    "        os.mkdir(temp_path + '/Train/C3')\n",
    "        os.mkdir(temp_path + '/Train/C4')\n",
    "        os.mkdir(temp_path + '/Test/C1')\n",
    "        os.mkdir(temp_path + '/Test/C2')\n",
    "        os.mkdir(temp_path + '/Test/C3')\n",
    "        os.mkdir(temp_path + '/Test/C4')\n",
    "\n",
    "            \n",
    "    except OSError:\n",
    "        return print (\"Creation of the directories failed\")\n",
    "    else:\n",
    "        return print (\"Successfully created the directories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b46c17-517d-44a6-ab42-cd25524ec664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Function If Test-Temp Folder Structure is not ready yet..\n",
    "#MakePathStructure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d21808-7174-4504-adb8-e78e4a8235c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and Separate in Imgages in Test and Train Folder\n",
    "def CopySeparateImagesToTestTrain():\n",
    "# Train Data\n",
    "    for i in range(len(X_train)):\n",
    "        origin_train_path = path + '/Data/train_images/'\n",
    "        source_file = X_train.iloc[i,1]\n",
    "        \n",
    "        #Seperate the classes into subfolders C0 and C1\n",
    "        if y_train.iloc[i] == 1:\n",
    "            target_directory = path + '/Data/Temp/Train/C1/'\n",
    "        elif y_train.iloc[i] == 2:\n",
    "            target_directory = path + '/Data/Temp/Train/C2/'\n",
    "        elif y_train.iloc[i] == 3:\n",
    "            target_directory = path + '/Data/Temp/Train/C3/'\n",
    "        elif y_train.iloc[i] == 4:\n",
    "            target_directory = path + '/Data/Temp/Train/C4/'\n",
    "            \n",
    "            \n",
    "        # Copy The Files\n",
    "        shutil.copy2(origin_train_path + source_file , target_directory + source_file)\n",
    "        \n",
    "    # Test Data\n",
    "    for i in range(len(X_test)):\n",
    "        origin_train_path = path + '/Data/train_images/'\n",
    "        source_file = X_test.iloc[i,1]\n",
    "        \n",
    "        #Seperate the classes into subfolders C0 and C1\n",
    "        if y_train.iloc[i] == 1:\n",
    "            target_directory = path + '/Data/Temp/Test/C1/'\n",
    "        elif y_train.iloc[i] == 2:\n",
    "            target_directory = path + '/Data/Temp/Test/C2/'\n",
    "        elif y_train.iloc[i] == 3:\n",
    "            target_directory = path + '/Data/Temp/Test/C3/'\n",
    "        elif y_train.iloc[i] == 4:\n",
    "            target_directory = path + '/Data/Temp/Test/C4/'\n",
    "        # Copy The Files\n",
    "        shutil.copy2(origin_train_path + source_file , target_directory + source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d003e-a2a8-4430-9071-b9eb772b8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function if files needs to copied into the subfolders und splitted into the classes\n",
    "path = os.getcwd()\n",
    "#CopySeparateImagesToTestTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f697510-cb4c-4ac2-953a-bbda574e62d4",
   "metadata": {},
   "source": [
    "## CNN Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf04926-d9e9-412b-b579-69db5430a8cd",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "https://keras.io/api/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5029ab4-bb78-4299-b82f-d4470ec76a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory\n",
    "path = os.getcwd()\n",
    "\n",
    "# Normalize the color values between 0 and 1\n",
    "datagen = ImageDataGenerator(rescale=1/255,\n",
    "rotation_range = 0,\n",
    "width_shift_range = 0.2,\n",
    "height_shift_range = 0.2,\n",
    "shear_range = 0,\n",
    "horizontal_flip = True)\n",
    "\n",
    "\n",
    "validation = ImageDataGenerator(rescale=1/255)\n",
    "batch_size = 32\n",
    "\n",
    "# Takes the path to a directory & generates batches of augmented data.\n",
    "train_generator = datagen.flow_from_directory( path + '/Data/Temp/Train/',\n",
    "                                          target_size=(128,512),   \n",
    "                                          #color_mode='grayscale',\n",
    "                                          batch_size = 32,\n",
    "                                          seed = 42,\n",
    "                                          class_mode = 'categorical')\n",
    "\n",
    "# Takes the path to a directory & generates batches of augmented data.\n",
    "validation_generator = validation.flow_from_directory(path + '/Data/Temp/Test/',\n",
    "                                          target_size=(128,512),\n",
    "                                          #color_mode='grayscale',\n",
    "                                          batch_size = 32,\n",
    "                                          seed = 42,\n",
    "                                          class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74afcca-e8ec-424f-a395-111078b0066e",
   "metadata": {},
   "source": [
    "## Analysis Outcome From Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da7d49-b399-4a44-9324-f1d5b3e335de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data labels are separated in following binary code: ' + str(validation_generator.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14190ce-fbdd-466f-a649-a4c126775821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_generator[..]\n",
    "print(type(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597abc2-96f2-49a6-8aff-237dd707eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and see the pictures and labels\n",
    "#img_batch, labels = next(validation_generator)\n",
    "#print('Shape of the input batch' + str(img_batch.shape))\n",
    "#print('Min of labels: ' + str(min(labels)) + ' and Max of labels: ' +str(max(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1941d0-c901-4646-9e5f-672b1f427c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image batch content\n",
    "#fig, ax = plt.subplots(int(len(img_batch) / 2), 2,constrained_layout=False)\n",
    "#                                                                            \n",
    "#for i in range(len(img_batch)):\n",
    "#    plt.subplot(int(len(img_batch) / 2), 2, i + 1)\n",
    "#    fig.set_figheight(30)\n",
    "#    fig.set_figwidth(20)\n",
    "#    plt.xlim(0,1600)\n",
    "#    plt.ylim(0,256)\n",
    "#    plt.imshow(img_batch[i])\n",
    "#    plt.text(100, 100, labels[i],color='r')\n",
    "#    \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89cb892-7430-4469-9546-a9a9facf5106",
   "metadata": {},
   "source": [
    "## Setup The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d637c-5759-480c-9f0c-cad3171c3604",
   "metadata": {},
   "source": [
    "https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0642d-aada-42c6-8064-2c7ddbb22687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "\n",
    "IMAGE_SIZE = [128, 512]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
    "\n",
    "# loading the weights of VGG16 without the top layer. These weights are trained on Imagenet dataset.\n",
    "vgg = VGG16(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)  # input_shape = (64,64,3) as required by VGG\n",
    "\n",
    "# this will exclude the initial layers from training phase as there are already been trained.\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "x = Dense(128, activation = 'relu')(x)   # we can add a new fully connected layer but it will increase the execution time.\n",
    "x = Dense(4, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
    "\n",
    "model = Model(inputs = vgg.input, outputs = x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd0622-6ab3-4393-bb77-98ab4b6c23ab",
   "metadata": {},
   "source": [
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275ad91-3dbf-42e8-b379-269693de0594",
   "metadata": {},
   "source": [
    "https://keras.io/api/models/model_training_apis/\n",
    "\n",
    "\n",
    "https://www.sciencedirect.com/topics/computer-science/one-hot-encodinghttps://www.sciencedirect.com/topics/computer-science/one-hot-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c89c53-3185-49a0-83c5-e772a1ae681c",
   "metadata": {},
   "source": [
    "## Train The CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e394311-262d-43ee-b731-b536b9eb1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, learning_rate, epochs):\n",
    "# RMSprop: Maintain a moving (discounted) average of the square of gradients\n",
    "# Divide the gradient by the root of this average\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate = learning_rate)\n",
    "    \n",
    "     \n",
    "    # Wie sehen die Labels der Loss-Funktion aus? Scalar? Hot-Encoding? Check Doku, was wird fuer binary_crossent. benoetigt\n",
    "    #https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class\n",
    "    #model.compile(loss =tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "     #             optimizer = opt,\n",
    "      #            metrics = ['accuracy'])\n",
    "\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    #https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#fit\n",
    "    # You may need to implement seed in fit?\n",
    "    history = model.fit(train_generator,\n",
    "              #steps_per_epoch = length_train // batch_size, # Number if images in train divided by batch size\n",
    "              epochs = epochs,\n",
    "              verbose = 1,\n",
    "              validation_data = validation_generator,\n",
    "              #validation_steps = length_test // batch_size,\n",
    "              callbacks=[tensorboard_callback]) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55bc1f4-b5f4-42aa-ab4c-80370a9fd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y =next(train_generator)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de637a5a-5a8a-4740-a336-d61632fb27ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y =next(validation_generator)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89dd55-8b2f-45d3-97a9-0dec99d17def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trained_model = train_model(model, batch_size, learning_rate = 0.01,epochs= 10)\n",
    "#model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4dfb0-6a16-4f07-80c2-675114cd8424",
   "metadata": {},
   "source": [
    "https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026f406-30bc-4358-ba50-23f0c0741c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "y_pred = model.predict(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10445fb7-e638-47e5-89de-369acab4f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd14b6c-ea57-4372-99e7-3614af3963bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(metrics.confusion_matrix(y_test,y_pred_), annot=True, cmap='YlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cc230-c075-474f-85b4-db1c94effad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915b9b3-169f-42c9-8133-2ade493cd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the TensorBoard Notebook Extension\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce81453-47e3-44ec-bd4a-5966858c84c5",
   "metadata": {},
   "source": [
    "## CNN Model Fitting Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bbe2d7-bf89-428f-9e9d-bbb1d77fd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4145cc0-dba2-4dbd-9bce-74f7c7bf9695",
   "metadata": {},
   "source": [
    "## CNN Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3cd79-cd5e-4e0b-9ba5-088db491de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate The Model Accuracy\n",
    "def evaluate_model(validation_generator):\n",
    "    model.evaluate(validation_generator)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d34fd5-d122-4282-884c-292dae69c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a714e37-2a25-414f-b69d-32427b0890f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the validation generator\n",
    "#STEP_SIZE_TEST = validation_generator.n // validation_generator.batch_size\n",
    "#validation_generator.reset()\n",
    "preds = model.predict(validation_generator, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
