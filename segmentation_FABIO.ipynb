{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caf4fedd-f5a9-4c50-bc4b-2fce228b533c",
   "metadata": {},
   "source": [
    "**Ressources**\n",
    "\n",
    "- [Convert Pandas DF into TF Dataset](https://medium.com/when-i-work-data/converting-a-pandas-dataframe-into-a-tensorflow-dataset-752f3783c168)\n",
    "- [Albumentations Doku](https://albumentations.ai/docs/getting_started/mask_augmentation/)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f140a-fae1-4505-9113-d140a685f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8452cc-e6a0-4750-ab55-f8e32cc6f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U albumentations --no-binary qudida,albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68476286-c10d-40b8-baef-9d0e166e26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove file directory for changed test run\n",
    "!rm -r data/segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c18924-cb8a-491e-ad00-9151d97fbd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import segmentation_models as sm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import data_preparation_cnn\n",
    "\n",
    "\n",
    "# Parameters\n",
    "DIMENSION = (256, 1600)\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "#Resizing images is optional, CNNs are ok with large images\n",
    "SIZE_X = 128 #Resize images (height  = X, width = Y)\n",
    "SIZE_Y = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a772fa-29bb-4d03-8f1f-e136ca57f908",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c58a0b73-172e-47e7-b54d-3b2dc106c2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FilePath</th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>Defect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/fabioteichmann/neuefische/projects/Caps...</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/fabioteichmann/neuefische/projects/Caps...</td>\n",
       "      <td>0007a71bf.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            FilePath        ImageId  ClassId  \\\n",
       "0  /Users/fabioteichmann/neuefische/projects/Caps...  0002cc93b.jpg        1   \n",
       "1  /Users/fabioteichmann/neuefische/projects/Caps...  0007a71bf.jpg        3   \n",
       "\n",
       "                                       EncodedPixels  Defect  \n",
       "0  29102 12 29346 24 29602 24 29858 24 30114 24 3...       1  \n",
       "1  18661 28 18863 82 19091 110 19347 110 19603 11...       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_complete.csv')\n",
    "\n",
    "# create data frame for defective pictures with added `Mask`\n",
    "defects = df.query('Defect == 1')\n",
    "defects.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd00a65-ef12-4367-91cc-d3f1ba2891c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Preparation for CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593de8c-17a7-4fd7-ac95-c782477147fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create images and masks and their respective augmentations for all 4 defect classes\n",
    "\n",
    "\"\"\"run time: ~ 4:15 \"\"\"\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "print('Starting data preparations')\n",
    "print('-----'*10)\n",
    "\n",
    "for i in range(4):\n",
    "    print()\n",
    "    data_preparation_cnn.prepare_data_for_class_id(df=defects, \n",
    "                                                   image_dimension=DIMENSION, \n",
    "                                                   seed=SEED, \n",
    "                                                   class_id=i+1, \n",
    "                                                   inverse_masks=True)\n",
    "    print()\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print('-----'*10)\n",
    "print('total time for preparations:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371d48e-4ed0-4fbc-a01c-8d6a46d65c57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### CNN-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30810f8a-05d3-4826-9071-f1f89757d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7a282-cc55-4fca-83d3-57ab11c596b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BACKBONE = 'resnet34'\n",
    "#preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "preprocess_input = sm.get_preprocessing('efficientnetb5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb0689e-4116-42d6-ad95-6d33da505188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3604, 128, 128, 3)\n",
      "(3604, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# load images and masks as input for model\n",
    "train_images, train_masks = data_preparation_cnn.get_resized_image_and_mask_lists(class_id=4, \n",
    "                                                                                  size_x=SIZE_X, \n",
    "                                                                                  size_y=SIZE_Y)\n",
    "print(train_images.shape)\n",
    "print(train_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca4d3b-8c5f-48fa-8086-853c8dd2393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use customary x_train and y_train variables\n",
    "X = train_images\n",
    "Y = train_masks\n",
    "print(X.shape, Y.shape)\n",
    "Y = np.expand_dims(Y, axis=3) #May not be necessary.. leftover from previous code \n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f039c-05b5-4f3a-ba3f-eaf7d21f2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# preprocess input\n",
    "x_train = preprocess_input(x_train)\n",
    "x_val = preprocess_input(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875cb9fe-3a11-465b-a129-d67c755c5766",
   "metadata": {},
   "source": [
    "#### Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a083e2-4343-4d1d-8242-e80762841e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.set_framework('tf.keras')\n",
    "\n",
    "sm.framework()\n",
    "# define model\n",
    "#model = sm.Unet()#BACKBONE, encoder_weights='imagenet')\n",
    "model = sm.Unet('efficientnetb5',classes=1,activation='sigmoid',encoder_weights='imagenet')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ffc172-d4f9-4937-ae93-2e0971e6b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c50851-a5bf-4997-bdbe-34b24f838c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x_train, \n",
    "          y_train,\n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8baf92d-2bd4-4004-8e9e-5f17a9356c24",
   "metadata": {},
   "source": [
    "#### Evaluation of the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c4b034-44c6-491b-a54c-34c4c263ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = model.evaluate(x_val, y_val)\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model.save('class2_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9b1c5-95d8-4388-86f6-057d9b0786ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf41df-e76e-4203-b3f6-81f40ea88dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('class2_test.h5', compile=False)\n",
    "#Test on a different image\n",
    "#READ EXTERNAL IMAGE...\n",
    "#data/segmentation/test/c1/1bed9264f.jpg\n",
    "# test_img = cv2.imread('data/segmentation/test/c1/0d4866e3c.jpg', cv2.IMREAD_COLOR)   \n",
    "# test_img = cv2.imread('data/segmentation/test/c1/1bed9264f.jpg', cv2.IMREAD_COLOR)  \n",
    "test_img = cv2.imread('data/segmentation/test/c1/04e23e414.jpg', cv2.IMREAD_COLOR) \n",
    "test_img = cv2.resize(test_img, (SIZE_Y, SIZE_X))\n",
    "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)\n",
    "print(test_img.shape)\n",
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc5da0-2fa3-43b2-88e0-aa0422e2ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704ab84-e20f-49f8-9f67-5fb65a54f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation = model.evaluate(x_val, y_val, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d64378-a932-4b82-8fea-5fc0c6e1eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b57de0-ce81-47f8-ac0c-7663588153bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View and Save segmented image\n",
    "prediction_image = prediction.reshape(mask.shape)\n",
    "plt.imshow(prediction_image, cmap='gray')\n",
    "plt.imsave('data/segmentation/test0_segmented.jpg', prediction_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8be4f-fe39-456f-be45-d5df85170dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/segmentation/test_mask/c1/mask_04e23e414.jpg'\n",
    "test_mask = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "test_mask = cv2.resize(test_mask, (SIZE_Y, SIZE_X))\n",
    "plt.imshow(test_mask, cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97d1b7-785b-4aaa-ad81-31bdec3bd4b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Model from Oxford-Tut (TO-DO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35a1529-71a8-4b1b-b122-eaf9202e9774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
    "\n",
    "# Use the activations of these layers\n",
    "layer_names = [\n",
    "                'block_1_expand_relu',   # 64x64\n",
    "                'block_3_expand_relu',   # 32x32\n",
    "                'block_6_expand_relu',   # 16x16\n",
    "                'block_13_expand_relu',  # 8x8\n",
    "                'block_16_project',      # 4x4\n",
    "]\n",
    "base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "\n",
    "down_stack.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9138b-614b-4220-b596-f19fdadc2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decoder/upsampler is simply a series of upsample blocks implemented in TensorFlow examples.\n",
    "\n",
    "up_stack = [\n",
    "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1a5c9-7ac9-4f06-80f7-b3c676c8e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(output_channels:int):\n",
    "    inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = down_stack(inputs)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "          filters=output_channels, kernel_size=3, strides=2,\n",
    "          padding='same')  #64x64 -> 128x128\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b6018-aaff-44ce-8350-bea15ae68058",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CLASSES = 2\n",
    "\n",
    "model = unet_model(output_channels=OUTPUT_CLASSES)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # expects `one_hot`\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b8d718-3c2c-4c65-825d-d170849da1e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995a533-e18f-4720-a07c-9f0349a109a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
    "# train_file_path = \"data/segmentation/train\"\n",
    "\n",
    "# train_data = tf.data.experimental.make_csv_dataset(train_file_path, \n",
    "#                                                    header=False, \n",
    "#                                                    field_delim='\\t', \n",
    "#                                                    column_names=['label', 'text'], \n",
    "#                                                    batch_size=64, \n",
    "#                                                    label_name='label', \n",
    "#                                                    num_epochs=1, \n",
    "#                                                    ignore_errors=True)\n",
    "\n",
    "# examples, labels = next(iter(train_data)) # Just the first batch.\n",
    "# print(\"FEATURES: \\n\", examples, \"\\n\")\n",
    "# print(\"LABELS: \\n\", labels)\n",
    "\n",
    "# encoder = keras.layers.TextVectorization(max_tokens=None, output_mode='int', output_sequence_length=160)\n",
    "# encoder.adapt(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c2a0a-8723-454c-abbf-684cb113e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df, complete=True):\n",
    "    if complete:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((tf.cast(df['FilePath'].values, tf.string),\n",
    "                                                      tf.cast(df['Mask'].values.tolist(), tf.float32)\n",
    "                                                     )\n",
    "                                                    )\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((tf.cast(df['FilePath'][:3000].values, tf.string),\n",
    "                                                      tf.cast(df['Mask'][:3000].values.tolist(), tf.float32)\n",
    "                                                     )\n",
    "                                                    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae5e02-1e45-4ea4-aa41-b6e0976728fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "# training_df = pd.DataFrame(\n",
    "#     data={'FilePath': defects.FilePath[:50],\n",
    "#           'Mask': defects.Mask[:50]\n",
    "#          }\n",
    "# )\n",
    "\n",
    "training_dataset = get_dataset(X_train, complete=False)\n",
    "\n",
    "# for features_tensor, target_tensor in training_dataset:\n",
    "#     print(f'features:{features_tensor} target:{target_tensor}')\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c6b0f6-b5bc-41c6-b2af-43e6b59d12dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31fbb68-15b0-424d-8f5b-8dc9b67bc741",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.from_tensor_slices((defects.FilePath[:10], list(defects.Mask[:10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711122a-6740-4515-9d1f-defbcbbaa70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797736ac-554b-4fc1-bd71-b3df475a7808",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Build Dataset for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c01289-bcd0-46b1-954b-bcc825dd8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset by re-esembling the splitted data\n",
    "dataset = {'train': X_train.join(y_train), 'test': X_test.join(y_test)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159930d-7bea-471e-b6cd-c5866b5c9d86",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Prepare the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20293666-2e0b-47ae-a4ac-8ac48cb9101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_mask -= 1\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7590cfa-e676-4737-bb16-d5d3ba38b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path, mask):\n",
    "    raw = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_png(raw, channels=3)\n",
    "    \n",
    "    input_image = image #tf.image.resize(image, (128, 128))\n",
    "    input_mask = mask #tf.image.resize(mask,#.reshape(mask.shape[0], mask.shape[1]), (128, 128))\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e021e2c-ae80-4d9e-af29-5024cab05f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = len(set(X_train.ImageId)) # number of unique `ImageIds`\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5811d0-6071-4912-bcef-3b9c4afed70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = training_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#test_images = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce617f3-f1d7-4159-b4f0-c1c525bda667",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06cedde-29ae-4aa1-8d94-fb12e6b5ade7",
   "metadata": {},
   "source": [
    "---\n",
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac99cdf-9b2b-49d2-95dd-61585438a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b0993-fb0e-49ce-9fa4-d6d5f7c3ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate `masks` for every image\n",
    "masks = []\n",
    "\n",
    "for i in range(len(defects.ClassId)):\n",
    "    #print(defects.EncodedPixels[i])\n",
    "    encoded_pixels = defects.EncodedPixels[i]\n",
    "    class_id = defects.ClassId[i]\n",
    "    mask = mask_conversion.decode_pixel(image_dimension=DIMENSION, \n",
    "                                        encoded_pixels=encoded_pixels, \n",
    "                                        class_id=class_id)\n",
    "    masks.append([mask.reshape(mask.shape[0]*mask.shape[1])])\n",
    "    \n",
    "\n",
    "masks_ = pd.DataFrame(masks, columns=['Mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7102b82-eea2-4d8a-8133-2360de20dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "defects = defects.join(masks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a201d8-2e84-4734-841e-90bd411228e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "defects.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6703a8-f095-4813-9e97-e7eb3cda3c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some masks\n",
    "for i in range(5):\n",
    "    mask = defects.Mask[i].reshape(mask.shape[0], mask.shape[1])\n",
    "\n",
    "    plt.figure(figsize=(25, 8))\n",
    "    plt.axis(\"off\")  \n",
    "    ax = plt.subplot(5, 1, i + 1)\n",
    "\n",
    "    plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182c10c-e48a-44e4-9cf7-51302decb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_pixels = defects.EncodedPixels[0]\n",
    "# class_id = defects.ClassId[0]\n",
    "# mask = mask_conversion.decode_pixel(image_dimension=DIMENSION, \n",
    "#                                     encoded_pixels=encoded_pixels, \n",
    "#                                     class_id=class_id)\n",
    "# mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad231fc-c980-4356-85a4-262b4b8830ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_flat = mask.reshape(mask.shape[0]*mask.shape[1])\n",
    "mask_unflat = mask_flat.reshape(mask.shape[0], mask.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12d5f6-dd59-4c2c-92bb-e3bd769394d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (mask_unflat == mask).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ba95d-5e32-4822-afff-df76279a4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defects.EncodedPixels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df899730-2746-4c2c-ac15-854a13cbeee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb31a7a-1b6c-4bfd-b6da-a70949fc372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FOR CLASSIFICATION\"\"\"\n",
    "\n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "# Normalize the color values between 0 and 1\n",
    "train = ImageDataGenerator(rescale=1/255)\n",
    "validation = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Takes the path to a directory & generates batches of augmented data.\n",
    "train_generator = train.flow_from_directory(path + '/data/segmentation/train/',\n",
    "                                            target_size=(256,1600),   #150,150\n",
    "                                            batch_size = 32,\n",
    "                                            save_format='jpg',\n",
    "                                            class_mode = 'sparse')\n",
    "\n",
    "# Takes the path to a directory & generates batches of augmented data.\n",
    "validation_generator = validation.flow_from_directory(path + '/data/segmentation/test/',\n",
    "                                          target_size=(256,1600),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd483b3c-b93f-4a5d-970d-d2032e8b281a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Externalized functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ff4aa-4d03-434e-9d78-db8e9542993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_dfs(df, seed):\n",
    "    X = df.copy()\n",
    "    y = X.pop('ClassId')\n",
    "\n",
    "    # Split into train and test set \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=seed)\n",
    "    \n",
    "    return X_train.join(y_train), X_test.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9080b1f5-ab11-4b1a-8d7a-b5bc66bbccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temp path for the train & test split\n",
    "def create_train_test_folders(subfolder, class_id):\n",
    "    print('preparing folders...')\n",
    "    path = os.getcwd()\n",
    "    #\n",
    "    ## You might need to adjust the path to your local environment\n",
    "    temp_path = path + \"/data/\" + subfolder\n",
    "    path_suffix = 'c' + str(class_id)\n",
    "    \n",
    "    # make base folder structure\n",
    "    try:\n",
    "        os.mkdir(temp_path)\n",
    "        \n",
    "        os.mkdir(temp_path + '/train')\n",
    "        os.mkdir(temp_path + '/train_aug')\n",
    "        \n",
    "        os.mkdir(temp_path + '/train_mask')\n",
    "        os.mkdir(temp_path + '/train_mask_aug')\n",
    "        \n",
    "        os.mkdir(temp_path + '/test')\n",
    "        os.mkdir(temp_path + '/test_mask')\n",
    "        print('base folder structure created')\n",
    "        \n",
    "    except OSError:\n",
    "        print('base folder structure exists')\n",
    "    \n",
    "    # make class specific sub-folder structure\n",
    "    try:\n",
    "        os.mkdir(temp_path + '/train/' + path_suffix)\n",
    "        os.mkdir(temp_path + '/train_aug/' + path_suffix)\n",
    "        os.mkdir(temp_path + '/train_mask/'+ path_suffix)\n",
    "        os.mkdir(temp_path + '/train_mask_aug/'+ path_suffix)\n",
    "        print(f'sub-folder structure for ClassId {class_id} created')\n",
    "        \n",
    "    except OSError:\n",
    "        print(f'sub-folder structure for ClassId {class_id} already exists')\n",
    "    \n",
    "    # make class specific sub-folder structure for test\n",
    "    try:\n",
    "        os.mkdir(temp_path + '/test/' + path_suffix)\n",
    "        os.mkdir(temp_path + '/test_mask/' + path_suffix)\n",
    "        print(f'sub-foder structure for testing for ClassId {class_id} created')\n",
    "        \n",
    "    except OSError:\n",
    "        print (\"Directories already exist\")\n",
    "    else:\n",
    "        print (\"Successfully created the directories\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c5c442-ec29-4d80-86e8-5feb1f5fcee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and Separate in Imgages in Test and Train Folder\n",
    "def copy_images_to_train_test(df_train, df_test, subfolder, class_id=2):\n",
    "    path = os.getcwd()\n",
    "    path_suffix = 'c' + str(class_id) + '/'\n",
    "    \n",
    "    create_train_test_folders(subfolder, class_id)\n",
    "    df_train = df_train.query('ClassId == @class_id')\n",
    "    df_test = df_test.query('ClassId == @class_id')\n",
    "    \n",
    "    print('copying images to folders...')\n",
    "\n",
    "    for i in range(len(df_train)):\n",
    "        #print(path)\n",
    "        # for training data\n",
    "        origin_train_path = path + '/data/train_images/'\n",
    "        source_file_train = df_train.iloc[i,1]\n",
    "        #print(source_file_train)\n",
    "        target_directory_train = path + '/data/' + subfolder + '/train/' + path_suffix\n",
    "        #print(origin_train_path)\n",
    "        #print(target_directory_train)\n",
    "        \n",
    "            \n",
    "        # Copy The Files\n",
    "        shutil.copy2(origin_train_path + source_file_train, target_directory_train + source_file_train)\n",
    "        try:\n",
    "            # for testing data\n",
    "            origin_test_path = path + '/data/train_images/'\n",
    "            source_file_test = df_test.iloc[i,1]\n",
    "            target_directory_test = path + '/data/' + subfolder + '/test/' + path_suffix\n",
    "\n",
    "            shutil.copy2(origin_test_path + source_file_test, target_directory_test + source_file_test)\n",
    "        except:\n",
    "            continue\n",
    "    print(f'Images successfully copied to {subfolder}!')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ec760-7662-4583-819b-0df20e4fe40d",
   "metadata": {},
   "source": [
    "#### Create Mask Pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824809ee-170b-44b2-abe8-ee68cc755be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pathlib\n",
    "\n",
    "def create_mask_image(image, image_id, encoded_pixels, inverse_masks):\n",
    "    # path = os.getcwd()\n",
    "    # target_directory = '/data/segmentation/train_mask/c1/'\n",
    "    image_name = 'mask_' + image_id\n",
    "    \n",
    "    # os.chdir(path + target_directory)\n",
    "    #print(target_directory.split('/')[0])\n",
    "    #print(path.joinpath(target_directory.split('/')[0], image_name))\n",
    "    if inverse_masks:\n",
    "        mask = mask_conversion.create_mask_with_class_id_inverted(DIMENSION,class_id=2,encoded_pixels=encoded_pixels)\n",
    "    else:\n",
    "        mask = mask_conversion.create_mask_with_class_id(DIMENSION,class_id=2,encoded_pixels=encoded_pixels)\n",
    "    mask *= 255\n",
    "    \n",
    "    written = cv2.imwrite(image_name, mask)\n",
    "    #print(written)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c6650-651d-49a6-b330-0a91a30004bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask_images(df, class_id, train=True, inverse_masks=False):\n",
    "    \"\"\"generates and saves mask images for `ClassId` 2\n",
    "    \"\"\"\n",
    "    print(f'generating mask images for ClassId {class_id} images...')\n",
    "    image_ids = df.query('ClassId == @class_id').ImageId\n",
    "\n",
    "    path = os.getcwd()\n",
    "    path_suffix = 'c' + str(class_id) + '/'\n",
    "    #print(path)\n",
    "    if train:\n",
    "        target_directory = '/data/segmentation/train_mask/' + path_suffix\n",
    "    else:\n",
    "        target_directory = '/data/segmentation/test_mask/' + path_suffix\n",
    "    # switch to target directory for saving process\n",
    "    os.chdir(path + target_directory)\n",
    "\n",
    "    for image_id in image_ids:\n",
    "        if train:\n",
    "            image = cv2.imread('data/segmentation/train/' + path_suffix + image_id)\n",
    "        else:\n",
    "            image = cv2.imread('data/segmentation/test/' + path_suffix + image_id)\n",
    "        encoded_pixels = defects.query('ImageId == @image_id and ClassId == @class_id')[['EncodedPixels']]\n",
    "        encoded_pixels = encoded_pixels.EncodedPixels.values[0]\n",
    "        create_mask_image(image, image_id, encoded_pixels, inverse_masks)\n",
    "    # switch back to home directory\n",
    "    os.chdir(path)\n",
    "    \n",
    "    print('mask images successfully generated!')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b754381-1401-43dc-b133-3126ff0afbda",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a025b-6828-4ed0-a00f-4e19fd68ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "augment = A.Compose([\n",
    "    #A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # A.OneOf([\n",
    "    #     A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
    "    #     A.GridDistortion(p=0.5),\n",
    "    #     A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)                  \n",
    "    #     ], p=0.8),\n",
    "    A.CLAHE(p=0.8),\n",
    "    A.RandomBrightnessContrast(p=0.8),    \n",
    "    A.RandomGamma(p=0.8)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef814c-ae3b-4d47-8f87-c951085566e5",
   "metadata": {},
   "source": [
    "#### Testing Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6942ca2-700b-47d1-b8ca-f091bf4b2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image, mask, original_image=None, original_mask=None):\n",
    "    fontsize = 18\n",
    "    \n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "        ax[0].imshow(image)\n",
    "        ax[1].imshow(mask)\n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 2, figsize=(12, 5))\n",
    "\n",
    "        ax[0, 0].imshow(original_image)\n",
    "        ax[0, 0].set_title('Original image', fontsize=fontsize)\n",
    "        \n",
    "        ax[1, 0].imshow(original_mask)\n",
    "        ax[1, 0].set_title('Original mask', fontsize=fontsize)\n",
    "        \n",
    "        ax[0, 1].imshow(image)\n",
    "        ax[0, 1].set_title('Transformed image', fontsize=fontsize)\n",
    "        \n",
    "        ax[1, 1].imshow(mask)\n",
    "        ax[1, 1].set_title('Transformed mask', fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b034d-3736-4ee2-9772-3ce704105f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread('data/segmentation/train/c1/060c3159e.jpg')\n",
    "original_mask = cv2.imread('data/segmentation/train_mask/c1/mask_060c3159e.jpg')\n",
    "\n",
    "augmented = augment(image=original_image, mask=original_mask)\n",
    "\n",
    "transformed_image = augmented['image']\n",
    "transformed_mask = augmented['mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe8bad-e298-4165-9ca8-249027fb0f56",
   "metadata": {},
   "source": [
    "If the image has multiple associated masks, you should use the `masks` argument instead of `mask`. In masks you should pass a list of masks.\n",
    "\n",
    "```python\n",
    "transformed = transform(image=image, masks=masks)\n",
    "transformed_image = transformed['image']\n",
    "transformed_masks = transformed['masks']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67fad3-ac75-4e6e-8cee-d8ee6acce8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(transformed_image, transformed_mask, original_image, original_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe93c85-5131-429c-bd15-79c661d2cb7c",
   "metadata": {},
   "source": [
    "#### Apply Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976166e8-18d6-4ff8-a52d-b5a8d3732d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "def augement_images_and_masks(image_ids, num_augmentations, class_id):\n",
    "    print(f'beginning augmentation for ClassId {class_id}...')\n",
    "    start = time.time()\n",
    "    \n",
    "    path = os.getcwd()\n",
    "    path_suffix = 'c' + str(class_id) + '/'\n",
    "    \n",
    "    target_directory_image = '/data/segmentation/train_aug/' + path_suffix\n",
    "    target_directory_mask = '/data/segmentation/train_mask_aug/' + path_suffix\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    while i <= num_augmentations:\n",
    "        #print(i)\n",
    "        number = random.randint(0, len(image_ids) -1)\n",
    "        image_id = image_ids[number]\n",
    "        mask_id = 'mask_' + image_id\n",
    "        #print(image_id, mask_id)\n",
    "        \n",
    "        original_image = cv2.imread('data/segmentation/train/' + path_suffix + image_id)\n",
    "        #print(type(original_image))\n",
    "        original_mask = cv2.imread('data/segmentation/train_mask/' + path_suffix + mask_id)\n",
    "        \n",
    "        augmented = augment(image=original_image, mask=original_mask)\n",
    "        transformed_image = augmented['image']\n",
    "        transformed_mask = augmented['mask']\n",
    "        \n",
    "        os.chdir(path + target_directory_image)\n",
    "        written = cv2.imwrite('aug_' + str(i) + '_' + image_id, transformed_image)\n",
    "        #print(written)\n",
    "        \n",
    "        os.chdir(path + target_directory_mask)\n",
    "        written = cv2.imwrite('aug_' + str(i) + '_' + mask_id, transformed_mask)\n",
    "        #print(written)\n",
    "        \n",
    "        os.chdir(path)\n",
    "        \n",
    "        i += 1\n",
    "    end = time.time()\n",
    "    print(f'augmented {num_augmentations} images of ClassId {class_id}')\n",
    "    print('time required for augmentation:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f76d5-e003-49f2-9452-1f43984374d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20854c28-f6c6-4516-bd48-59971fb6aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e206994-bf54-4cc6-8cb1-57ba7ac99314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import argv\n",
    "image_ids = Xy_train.query('ClassId == 2').ImageId.values\n",
    "print(len(image_ids))\n",
    "nr = 0\n",
    "#for id_ in image_ids:\n",
    "    #print(os.path.exists('data/segmentation/train/c1/' + id_))\n",
    "    # if os.access('data/segmentation/train/c1/' + image_id, os.R_OK):\n",
    "    #     continue\n",
    "    # else:\n",
    "    #     nr += 1\n",
    "        \n",
    "print(nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9341d7-7dd3-4a52-bdcf-1e33f620b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 'a41ba727f.jpg'\n",
    "original_image = cv2.imread('data/segmentation/train/c1/' + image_id)\n",
    "print(os.access('data/segmentation/train/c1/' + image_id, os.R_OK))\n",
    "print(os.path.exists('data/segmentation/train/c1/' + image_id))\n",
    "print('data/segmentation/train/c1/' + image_id)\n",
    "plt.imshow(original_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803ad1d-35e1-4d56-8385-c215352fec22",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55033e50-dbb5-457c-9ac3-960a85122937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_class_id(df, image_dimension, seed, class_id, inverse_masks):\n",
    "    \"\"\"combines all data preparations:\n",
    "    - creating required folder structure\n",
    "    - copying images to folders according to train-test-split using `seed`\n",
    "    - generating masks for all images of `class_id`\n",
    "    - augmenting images and corresponding masks\n",
    "    \n",
    "    Input parameters:\n",
    "    df            - data frame that contains all defects and the `FilePaths` to all images\n",
    "    seed          - seed for `train_test_split`\n",
    "    class_id      - id of defect class\n",
    "    inverse_masks - if `True`, defect pixels will be white, pixels without defect will be black\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Starting data preparations')\n",
    "    print('-----'*10)\n",
    "    \n",
    "    start = time.time()\n",
    "    # split data into train and test\n",
    "    df_train, df_test = data_preparation_cnn.create_train_test_dfs(df, seed)\n",
    "    \n",
    "    subfolder = 'segmentation'\n",
    "    # sort images according to train-test-split\n",
    "    data_preparation_cnn.copy_images_to_train_test(df_train, df_test, subfolder, class_id)\n",
    "    \n",
    "    # generate mask images for train and test data\n",
    "    data_preparation_cnn.generate_mask_images(df, class_id, image_dimension, train=True, inverse_masks=inverse_masks)\n",
    "    data_preparation_cnn.generate_mask_images(df, class_id, image_dimension, train=False, inverse_masks=inverse_masks)\n",
    "    \n",
    "    # augment images and masks where needed\n",
    "    image_ids = df_train.query('ClassId == @class_id').ImageId.values\n",
    "    num_augmentations = max(df_train.groupby('ClassId').count().ImageId)\n",
    "    \n",
    "    data_preparation_cnn.augement_images_and_masks(image_ids=image_ids, \n",
    "                                                   num_augmentations=num_augmentations, \n",
    "                                                   class_id=class_id)\n",
    "    end = time.time()\n",
    "    \n",
    "    print('data successfully prepared for the model!')\n",
    "    print('time elapsed:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c92f6f-02f0-4a03-bd81-8bac08595f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418abc2-20b0-417f-bbb7-4e6097150702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask_to_df(df):\n",
    "    # Generate `masks` for every image\n",
    "    masks = []\n",
    "\n",
    "    for i in range(len(df.ClassId)):\n",
    "        #print(defects.EncodedPixels[i])\n",
    "        encoded_pixels = df.EncodedPixels[i]\n",
    "        class_id = df.ClassId[i]\n",
    "        mask = mask_conversion.decode_pixel(image_dimension=DIMENSION, \n",
    "                                            encoded_pixels=encoded_pixels, \n",
    "                                            class_id=class_id)\n",
    "        masks.append([mask.reshape(mask.shape[0]*mask.shape[1])])\n",
    "\n",
    "\n",
    "    masks_ = pd.DataFrame(masks, columns=['Mask'])\n",
    "    \n",
    "    return df.join(masks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc6147-eb08-46c3-8fa4-4e70c51a39a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
