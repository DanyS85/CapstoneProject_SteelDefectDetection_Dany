{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5afd02-1b30-425d-93d0-b88273c055ce",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network - Binary Classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2413f36-dd89-49dc-863d-3a649c3c9ce4",
   "metadata": {},
   "source": [
    "\n",
    "#### Intro to binary CNN\n",
    "https://towardsdatascience.com/10-minutes-to-building-a-cnn-binary-image-classifier-in-tensorflow-4e216b2034aa\n",
    "\n",
    "#### Code inspiration from here..\n",
    "\n",
    "https://medium.com/techiepedia/binary-image-classifier-cnn-using-tensorflow-a3f5d6746697 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569336d3-cf7f-419a-85d5-10378c2fefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries that might be installed beforehand\n",
    "\n",
    "#!pip install opencv-python\n",
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c414e0-0149-483d-b346-1943ab6b5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# CNN Envrionment\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Miscellaneous\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "# Python Scripts\n",
    "#import sys  \n",
    "#sys.path.insert(0, './Python_Scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47589bfa-f683-4bdb-b537-9921f1487387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Tensorflow version\n",
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e9033-3b8d-4b02-8dcf-087a693c377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('Data/train_complete.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20025832-82b1-4522-bc01-2eaa3a1fd0c4",
   "metadata": {},
   "source": [
    "## Convert from RGB to Gray-Scale:\n",
    "\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/image/rgb_to_grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c83f3-31d2-4970-af09-f9302aeb137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grey-Scaling\n",
    "original =  plt.imread('./Data/train_images/' + str(df.ImageId[0]))\n",
    "\n",
    "converted = tf.image.rgb_to_grayscale(original)\n",
    "\n",
    "print(original.shape)\n",
    "print(converted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488238a4-96e6-43f3-9682-e46fe1e0b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure as subplots\n",
    "fig, ax = plt.subplots(2, 1, constrained_layout=True, figsize=(25, 10))\n",
    "\n",
    "# Subplot 1\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(original)\n",
    "plt.xlim(0,1600)\n",
    "plt.ylim(0,256)\n",
    "ax[0].set_title('Original', fontsize= 24)\n",
    "\n",
    "\n",
    "# Subplot 2\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(converted)\n",
    "plt.xlim(0,1600) \n",
    "plt.ylim(0,256)\n",
    "ax[1].set_title('Grey-Scaled', fontsize= 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f8340-636a-4e92-9ad0-fcd10b8e50d1",
   "metadata": {},
   "source": [
    "## Test Split and Data Storage Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779f9a5-98e2-4d4c-a227-deab76aaa9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Do the test split\n",
    "#index = df.ClassId == 3 \n",
    "#df = df[index] \n",
    "df_red = df.query('Defect == 1')\n",
    "\n",
    "X = df_red.iloc[:,0:4]\n",
    "y = df_red.iloc[:,2]\n",
    "\n",
    "df_red.loc[df['ClassId'] == 3,'ClassId'] = 0\n",
    "df_red.loc[df['ClassId'] == 1,'ClassId'] = 1\n",
    "df_red.loc[df['ClassId'] == 1,'ClassId'] = 1\n",
    "df_red.loc[df['ClassId'] == 4,'ClassId'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d472a-db03-4e64-a612-b893ba308680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155c790-3799-4dd3-8c24-cf3156dcc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state = 1)\n",
    "length_train = len(y_train)\n",
    "length_test = len(y_test)\n",
    "print('Length of Train-Set: ' + str(len(y_train)))\n",
    "print('Length of Test-Set: ' + str(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f3ae9-8e71-4c00-a669-24ea75ac2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check No-Defect Distributions\n",
    "print('No-Defect-Ratio in Train: ' + str(round((y_train == 0).astype(int).sum(axis=0) / len(y_train),4)))\n",
    "print('No-Defect-Ratio in Test: ' + str(round((y_test == 0).astype(int).sum(axis=0) / len(y_test),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0eb3f-8799-4093-983e-085fd693cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvertToGrayScale\n",
    "def ConvertToGrayScale(file_name, input_path, target_path):\n",
    "    #original =  plt.imread(input_path + file_name)\n",
    "    original = tf.keras.utils.load_img(input_path + file_name, grayscale=False, color_mode='rgb', target_size=None)\n",
    "    converted = tf.image.rgb_to_grayscale(original)\n",
    "    tf.keras.utils.save_img(target_path + file_name, converted, data_format=None, file_format=None, scale=True)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806bdb36-d230-4eb5-a16e-49fb753cc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excute ConvertToGrayScale Function\n",
    "#input_path = './Data/train_images/'\n",
    "#target_path = './Data/train_images_GrayScaled/'\n",
    "#for i in range(len(df.ImageId)):\n",
    "#    file_name = df.ImageId[i]\n",
    "#    ConvertToGrayScale(file_name, input_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d821e-a997-4ccb-b61f-afd9b29c652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temp path for the train & test split\n",
    "def MakePathStructure():\n",
    "    path = os.getcwd()\n",
    "    \n",
    "    ## You might need to adjust the path to your local environment\n",
    "    temp_path = path + \"/Data/Temp\"\n",
    "    \n",
    "    # Make DirectoryTemp and Sub-Directories Train & Test\n",
    "    try:\n",
    "        #os.mkdir(temp_path)\n",
    "        os.mkdir(temp_path + '/C3vsRemain_Train')\n",
    "        os.mkdir(temp_path + '/C3vsRemain_Test')\n",
    "        os.mkdir(temp_path + '/C3vsRemain_Train/C0')\n",
    "        os.mkdir(temp_path + '/C3vsRemain_Train/C1')\n",
    "        os.mkdir(temp_path + '/C3vsRemain_Test/C0')\n",
    "        os.mkdir(temp_path + '/C3vsRemain_Test/C1')\n",
    "            \n",
    "    except OSError:\n",
    "        return print (\"Creation of the directories failed\")\n",
    "    else:\n",
    "        return print (\"Successfully created the directories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b46c17-517d-44a6-ab42-cd25524ec664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Function If Test-Temp Folder Structure is not ready yet..\n",
    "#MakePathStructure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d21808-7174-4504-adb8-e78e4a8235c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and Separate in Imgages in Test and Train Folder\n",
    "def CopySeparateImagesToTestTrain():\n",
    "# Train Data\n",
    "    for i in range(len(X_train)):\n",
    "        origin_train_path = path + '/Data/train_images_GrayScaled/'\n",
    "        source_file = X_train.iloc[i,1]\n",
    "        \n",
    "        #Seperate the classes into subfolders C0 and C1\n",
    "        if y_train.iloc[i] == 0:\n",
    "            target_directory = path + '/Data/Temp/C3vsRemain_Train/C0/'\n",
    "        else:\n",
    "            target_directory = path + '/Data/Temp/C3vsRemain_Train/C1/'\n",
    "        # Copy The Files\n",
    "        shutil.copy2(origin_train_path + source_file , target_directory + source_file)\n",
    "        \n",
    "    # Test Data\n",
    "    for i in range(len(X_test)):\n",
    "        origin_train_path = path + '/Data/train_images_GrayScaled/'\n",
    "        source_file = X_test.iloc[i,1]\n",
    "        \n",
    "        #Seperate the classes into subfolders C0 and C1\n",
    "        if y_train.iloc[i] == 0:\n",
    "            target_directory = path + '/Data/Temp/C3vsRemain_Test/C0/'\n",
    "        else:\n",
    "            target_directory = path + '/Data/Temp/C3vsRemain_Test/C1/'\n",
    "        # Copy The Files\n",
    "        shutil.copy2(origin_train_path + source_file , target_directory + source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d003e-a2a8-4430-9071-b9eb772b8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function if files needs to copied into the subfolders und splitted into the classes\n",
    "#CopySeparateImagesToTestTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f697510-cb4c-4ac2-953a-bbda574e62d4",
   "metadata": {},
   "source": [
    "## CNN Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf04926-d9e9-412b-b579-69db5430a8cd",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "https://keras.io/api/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5029ab4-bb78-4299-b82f-d4470ec76a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory\n",
    "path = os.getcwd()\n",
    "\n",
    "# Normalize the color values between 0 and 1\n",
    "datagen = ImageDataGenerator(rescale=1/255,\n",
    "rotation_range = 20,\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range = 0.1,\n",
    "shear_range = 10,\n",
    "horizontal_flip = True)\n",
    "\n",
    "\n",
    "validation = ImageDataGenerator(rescale=1/255)\n",
    "batch_size = 32\n",
    "# Takes the path to a directory & generates batches of augmented data.\n",
    "train_generator = datagen.flow_from_directory( path + '/Data/Temp/C3vsRemain_Train/',\n",
    "                                          target_size=(256,1600),   \n",
    "                                          color_mode='grayscale',\n",
    "                                          batch_size = batch_size,\n",
    "                                          seed = 1,\n",
    "                                          class_mode = 'binary')\n",
    "\n",
    "# Takes the path to a directory & generates batches of augmented data.\n",
    "validation_generator = datagen.flow_from_directory(path + '/Data/Temp/C3vsRemain_Test/',\n",
    "                                          target_size=(256,1600),\n",
    "                                          color_mode='grayscale',\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74afcca-e8ec-424f-a395-111078b0066e",
   "metadata": {},
   "source": [
    "## Analysis Outcome From Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da7d49-b399-4a44-9324-f1d5b3e335de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data labels are separated in following binary code: ' + str(validation_generator.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14190ce-fbdd-466f-a649-a4c126775821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_generator[..]\n",
    "print(type(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597abc2-96f2-49a6-8aff-237dd707eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate and see the pictures and labels\n",
    "img_batch, labels = next(validation_generator)\n",
    "print('Shape of the input batch' + str(img_batch.shape))\n",
    "print('Min of labels: ' + str(min(labels)) + ' and Max of labels: ' +str(max(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1941d0-c901-4646-9e5f-672b1f427c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image batch content\n",
    "fig, ax = plt.subplots(int(len(img_batch) / 2), 2,constrained_layout=False)\n",
    "                                                                            \n",
    "for i in range(len(img_batch)):\n",
    "    plt.subplot(int(len(img_batch) / 2), 2, i + 1)\n",
    "    fig.set_figheight(30)\n",
    "    fig.set_figwidth(20)\n",
    "    plt.xlim(0,1600)\n",
    "    plt.ylim(0,256)\n",
    "    plt.imshow(img_batch[i])\n",
    "    plt.text(100, 100, labels[i],color='r')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89cb892-7430-4469-9546-a9a9facf5106",
   "metadata": {},
   "source": [
    "## Setup The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d637c-5759-480c-9f0c-cad3171c3604",
   "metadata": {},
   "source": [
    "https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9a85b-7340-4a87-878a-796f47222aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model_base():\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    \n",
    "    # Convolutional layer 1: \n",
    "    # This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
    "    # Maybe increase the filter size e.g. 9x9\n",
    "    model.add(keras.layers.Conv2D(16,(3,3), # 16 Filters and 3x3 Kernel\n",
    "                                  activation='relu', \n",
    "                                  input_shape=(256,1600,1),\n",
    "                                  strides = (3,3),\n",
    "                                  padding=\"valid\"))\n",
    "    \n",
    "    # Check more network structures --> \n",
    "    # Check Image After Rezising!!  \n",
    "    #model.add(keras.layers.Resizing(int(256), int(1600), interpolation=\"bilinear\", crop_to_aspect_ratio=True))\n",
    "    \n",
    "    #The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, \n",
    "    #which helps prevent overfitting.\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #MaxPooling makes network invariant to small translations\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2,2), strides = (2,2), padding=\"same\")) \n",
    "    \n",
    "    \n",
    "    # Convolutional layer and maxpool layer 2\n",
    "    model.add(keras.layers.Conv2D(32,(3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2,2), strides = (2,2), padding=\"same\")) \n",
    "    \n",
    "    # Convolutional layer and maxpool layer 3\n",
    "    model.add(keras.layers.Conv2D(32,(3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2,2), strides = (2,2), padding=\"same\")) \n",
    "    \n",
    "    # Convolutional layer and maxpool layer 4\n",
    "    model.add(keras.layers.Conv2D(64,(3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2,2), strides = (2,2), padding=\"same\")) \n",
    "    \n",
    "    # Convolutional layer and maxpool layer 5\n",
    "    model.add(keras.layers.Conv2D(64,(3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2,2), strides = (2,2), padding=\"same\")) \n",
    "     \n",
    "    # This layer flattens resulting image array to 1D array\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    # Hidden layer 1: with XXX neurons and Rectified Linear Unit Activation Function \n",
    "    model.add(keras.layers.Dense(256,activation='relu'))\n",
    "    \n",
    "    # Hidden layer 2\n",
    "    model.add(keras.layers.Dense(512,activation='relu'))\n",
    "    \n",
    "    # Hidden layer 3\n",
    "    model.add(keras.layers.Dense(512,activation='relu'))\n",
    "    \n",
    "    # Output layer with single neuron which gives 0 for Non-Failure or 1 for Failure \n",
    "    #Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
    "    model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8c0c4-d30d-4a7f-9e6a-5c9bc823626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_model():\n",
    "    model_VGG16 = keras.Sequential()\n",
    "    \n",
    "    model_VGG16.add(Conv2D(input_shape=(128,800,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "    #model_VGG16.add(keras.layers.Resizing(int(256/8), int(1600/8), interpolation=\"bilinear\", crop_to_aspect_ratio=True))\n",
    "    model_VGG16.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model_VGG16.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model_VGG16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model_VGG16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model_VGG16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model_VGG16.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "\n",
    "    model_VGG16.add(Flatten())\n",
    "    model_VGG16.add(Dense(units=4096,activation=\"relu\")) #4096\n",
    "    model_VGG16.add(Dense(units=4096,activation=\"relu\")) #4096\n",
    "    \n",
    "    model_VGG16.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "    model = model_VGG16\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd0622-6ab3-4393-bb77-98ab4b6c23ab",
   "metadata": {},
   "source": [
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa858088-cd6d-4b9f-b76c-5a3416f8af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the CNN model as set before\n",
    "model = CNN_model_base()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275ad91-3dbf-42e8-b379-269693de0594",
   "metadata": {},
   "source": [
    "https://keras.io/api/models/model_training_apis/\n",
    "\n",
    "\n",
    "https://www.sciencedirect.com/topics/computer-science/one-hot-encodinghttps://www.sciencedirect.com/topics/computer-science/one-hot-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c89c53-3185-49a0-83c5-e772a1ae681c",
   "metadata": {},
   "source": [
    "## Train The CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e394311-262d-43ee-b731-b536b9eb1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, learning_rate, epochs):\n",
    "# RMSprop: Maintain a moving (discounted) average of the square of gradients\n",
    "# Divide the gradient by the root of this average\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate = learning_rate)\n",
    "    \n",
    "     \n",
    "    # Wie sehen die Labels der Loss-Funktion aus? Scalar? Hot-Encoding? Check Doku, was wird fuer binary_crossent. benoetigt\n",
    "    #https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class\n",
    "    model.compile(loss =tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "                  optimizer = opt,\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    #https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#fit\n",
    "    # You may need to implement seed in fit?\n",
    "    history = model.fit(train_generator,\n",
    "              steps_per_epoch = length_train // batch_size, # Number if images in train divided by batch size\n",
    "              epochs = epochs,\n",
    "              verbose = 1,\n",
    "              validation_data = validation_generator,\n",
    "              validation_steps = length_test // batch_size,\n",
    "              callbacks=[tensorboard_callback]) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89dd55-8b2f-45d3-97a9-0dec99d17def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trained_model = train_model(model, batch_size, learning_rate = 0.01, epochs = 5)\n",
    "#model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4dfb0-6a16-4f07-80c2-675114cd8424",
   "metadata": {},
   "source": [
    "https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915b9b3-169f-42c9-8133-2ade493cd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the TensorBoard Notebook Extension\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce81453-47e3-44ec-bd4a-5966858c84c5",
   "metadata": {},
   "source": [
    "## CNN Model Fitting Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bbe2d7-bf89-428f-9e9d-bbb1d77fd069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4145cc0-dba2-4dbd-9bce-74f7c7bf9695",
   "metadata": {},
   "source": [
    "## CNN Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3cd79-cd5e-4e0b-9ba5-088db491de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate The Model Accuracy\n",
    "def evaluate_model(validation_generator):\n",
    "    model.evaluate(validation_generator)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d34fd5-d122-4282-884c-292dae69c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a714e37-2a25-414f-b69d-32427b0890f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the validation generator\n",
    "#STEP_SIZE_TEST = validation_generator.n // validation_generator.batch_size\n",
    "#validation_generator.reset()\n",
    "preds = model.predict(validation_generator, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
