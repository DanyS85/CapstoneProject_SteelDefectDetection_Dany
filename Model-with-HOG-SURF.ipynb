{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc6522-3b7f-4105-a961-dbb1ad514157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage.transform import resize\n",
    "import math\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import data, exposure\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd7e7c-2a75-42e2-ba72-597bfa4c29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cfa37-432f-4963-a7f6-a6eaf5465ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import util\n",
    "import surf_hog_analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99da101-fa89-491a-a54b-21504bfd7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d4c01-ded7-46ba-82f3-b9a806e91861",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e98c659-508c-4d9c-8c8f-fa56a048cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be27cc72-3149-4f93-8e21-248b06b16d69",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53049e54-adfc-4e0d-8592-16dc33039f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e98c4-acbd-400e-a87c-6655780834a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of `ImageId` in df\n",
    "df['count'] = df.ImageId.apply(lambda x: df['ImageId'].value_counts()[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcbd573-2f46-4f83-a74c-acce35305d7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c71ca-ce56-435b-b117-63ba9fda0901",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Use HoG Feature Vector (based on 4 imbalanced classes in train_images) in KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af16d3-acd3-4cac-9574-a012aa09b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = pd.read_csv('data/train_HOG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05fe91f-8e66-4775-870a-3d277c4711e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate only images that have 0 or 1 defect\n",
    "util.isolate_single_defects(hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02f2fb-f633-4532-928f-ed278e88a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_complete = hog.merge(df[['ClassId','ImageId']], on = 'ImageId')\n",
    "hog_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af2300-bd1f-4350-8218-83bab0592d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate class 0 in dataframe\n",
    "hog_complete = hog_complete.query('ClassId != 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cabad3a-bcae-4d60-a53f-1f38e25e5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_complete.groupby('ClassId')['ImageId'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b67ad-2cde-4acf-8136-a952df5a3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Hog_complete in X und Y\n",
    "X = hog_complete.drop(['ClassId','ImageId'], axis =1)\n",
    "y = hog_complete['ClassId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdb4a5a-419d-44e8-8839-173165360df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split without oversampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y, random_state = 42)\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089cc6f-6c7d-4f47-bba7-2fe3fc50c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling with RandomOversampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f0a7d-9861-426f-b0dd-9af0ad0674b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling with SMOTE\n",
    "X_train_smo, y_train_smo = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb9293-5668-4ddb-8302-c7c4fe364255",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_train_scaled = scaler.fit_transform(X_train_ros)\n",
    "#X_train_scaled = scaler.fit_transform(X_train_smo)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3,algorithm='brute')\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "#classifier.fit(X_train_scaled, y_train_ros)\n",
    "#classifier.fit(X_train_scaled, y_train_smo)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "test_accuracy = classifier.score((X_test_scaled), y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb420c1-71e9-47b7-b72f-b563d4b451aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ba3bf-0a2c-4dfc-9b26-2891a79b1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4180957e-b4ba-4687-80c7-b95daee3f638",
   "metadata": {},
   "source": [
    "#### results without oversampling   \n",
    "    \n",
    "           precision    recall  f1-score   support\n",
    "\n",
    "           0       0.74      0.88      0.81      1181\n",
    "           1       0.46      0.56      0.51       154\n",
    "           2       0.38      0.72      0.50        39\n",
    "           3       0.87      0.70      0.77       952\n",
    "           4       0.67      0.02      0.04       103\n",
    "\n",
    "    accuracy                           0.75      2429\n",
    "   macro avg       0.63      0.58      0.53      2429\n",
    "weighted avg       0.77      0.75      0.74      2429"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28d179-c7cc-4046-acb5-8f1d2ed94852",
   "metadata": {},
   "source": [
    "#### results with random oversampling  \n",
    "           precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.80      0.80      1181\n",
    "           1       0.35      0.73      0.47       154\n",
    "           2       0.31      0.82      0.45        39\n",
    "           3       0.85      0.71      0.77       952\n",
    "           4       0.44      0.11      0.17       103\n",
    "\n",
    "    accuracy                           0.73      2429\n",
    "   macro avg       0.55      0.63      0.53      2429\n",
    "weighted avg       0.77      0.73      0.74      2429"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcedce40-28e3-4a0b-bd69-d6d4abb92884",
   "metadata": {},
   "source": [
    "#### results with SMOTE oversampling  \n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.39      0.55      1181\n",
    "           1       0.15      0.85      0.25       154\n",
    "           2       0.17      0.87      0.29        39\n",
    "           3       0.87      0.53      0.66       952\n",
    "           4       0.19      0.56      0.28       103\n",
    "\n",
    "    accuracy                           0.49      2429\n",
    "   macro avg       0.47      0.64      0.41      2429\n",
    "weighted avg       0.84      0.49      0.56      2429"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3d061-e6f8-4b59-898a-c8dd7ea6aa65",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Visualization of falsely predicted pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9b4f7-85ab-49f9-a82f-6c0dbb677687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#surf_hog_analysis.print_false_classifications(df, hog_complete, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e00cdc-6404-423f-95e3-94585cfc7127",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Piece-by-piece visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e1b9f-5b42-4326-80c0-c0069fa0f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract indices of our `hog_complete` data frame where predictions were incorrect\n",
    "false_predictions = (y_pred!=y_test)\n",
    "false_predictions = false_predictions[false_predictions].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cdaad0-1830-4e1d-a304-57f6c843449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[(y_pred!=y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5413f-a24e-4146-bd9b-ce66d14d51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_false =y_pred[(y_pred!=y_test)]\n",
    "\n",
    "predictions = pd.DataFrame(y_pred_false, index=false_predictions,columns=['ClassId_predicted'])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4545fe4-de5f-45ed-84d3-2fd205ee6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all rows from `hog_complete` where the predcition was incorrect\n",
    "false_predicted_images = hog_complete.join(predictions).loc[false_predictions][['ImageId','ClassId', 'ClassId_predicted']]\n",
    "# add additional information needed to find the correponding pictures\n",
    "false_predicted_images = false_predicted_images.merge(df[['FilePath','ImageId']], on = 'ImageId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0cee3-8954-4cb6-95b0-776298b9e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_predicted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461c650e-671d-4392-9481-c3cc941df0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_images = 5\n",
    "\n",
    "random_index = np.round(np.random.rand(number_images) * len(false_predicted_images.ImageId)) + 1\n",
    "#print(random_index)\n",
    "\n",
    "for i in range(number_images):\n",
    "    #random_index = 'random_index_' + str(i+1)\n",
    "    #print(random_index)\n",
    "    file_path_to_image = false_predicted_images['FilePath'][random_index[i]]\n",
    "    class_id = false_predicted_images['ClassId'][random_index[i]]\n",
    "    image_id = false_predicted_images['ImageId'][random_index[i]]\n",
    "    class_id_pred = int(false_predicted_images['ClassId_predicted'][random_index[i]])\n",
    "    \n",
    "    img = io.imread(file_path_to_image)\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    ax = plt.subplot(number_images, 1, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Image ID: {image_id} | True ClassId: {class_id} | Predicted ClassId: {class_id_pred}', fontsize=16);\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "\"\"\"\n",
    "file_path_to_image = false_predicted_images['FilePath'][random_index]\n",
    "class_id = false_predicted_images['ClassId'][random_index]\n",
    "image_id = false_predicted_images['ImageId'][random_index]\n",
    "class_id_pred = int(false_predicted_images['ClassId_predicted'][random_index])\n",
    "print(image_id)\n",
    "\n",
    "img = io.imread(file_path_to_image)\n",
    "\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.imshow(img)\n",
    "plt.title(f'Image ID: {image_id} | True ClassId: {class_id} | Predicted ClassId: {class_id_pred}', fontsize=16);\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac58d7-a3ba-494b-af76-be0868acb98f",
   "metadata": {},
   "source": [
    "## Use HoG Feature Vector (based on augmented train_images; balanced) in KNN\n",
    "#### Use augmented hog pictures for Training an initial hog pictures (hog_complete) for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f882b-458b-4a54-823a-31eab1babeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/train_single_defects_augmented.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07064832-9cf5-41ee-a8bc-047b0ab13e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented pictures are based on single defect pictures of classes 1-4\n",
    "hog_augmented = pd.read_csv('data/train_HOG_augmented.csv')\n",
    "hog_augmented.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be36a96-fdb4-4411-80ff-1e657755d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_augmented_complete = hog_augmented.merge(df2[['ClassId','ImageId']], on = 'ImageId')\n",
    "hog_augmented_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b47bb8-3c3e-41ec-b8fc-415bcb38f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_augmented_complete.groupby('ClassId')['ImageId'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c45ee1d-89bb-4851-923a-7be95eb23ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: use augmented hog pictures for Training an initial hog pictures (hog_complete) for test\n",
    "#Split Hog_complete in X und Y\n",
    "X_train = hog_augmented_complete.drop(['ClassId','ImageId'], axis =1)\n",
    "y_train = hog_augmented_complete['ClassId']\n",
    "\n",
    "# eliminate \"class 0\" in hog_complete\n",
    "hog_complete2 = hog_complete.query('ClassId != 0')\n",
    "X_test = hog_complete2.drop(['ClassId','ImageId'], axis =1)\n",
    "y_test = hog_complete2['ClassId']\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a0e7d-4a4c-4307-83a4-aff56003d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_accuracy = []\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3,algorithm='brute')\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "test_accuracy = classifier.score((X_test_scaled), y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324869e-25a2-4f69-b1d5-aacde8e8124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014a719-a5ec-468d-a5a3-8636e6788787",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b3ad2-fce5-4c91-8566-38dfdd298fc3",
   "metadata": {},
   "source": [
    "###  same model without class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087345a6-d5e4-49fb-bb52-2aeb3f3c9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Idea: use augmented hog pictures for Training an initial hog pictures (hog_complete) for test\n",
    "#Split Hog_complete in X und Y\n",
    "# eliminate \"class 3 \" in hog_augmented_complete\n",
    "hog_augmented_complete2 = hog_augmented_complete.query('ClassId != 3') \n",
    "X_train = hog_augmented_complete2.drop(['ClassId','ImageId'], axis =1)\n",
    "y_train = hog_augmented_complete2['ClassId']\n",
    "\n",
    "# eliminate \"class 3\" in hog_complete2 (Class 0 is already eliminated)\n",
    "hog_complete3 = hog_complete2.query('ClassId != 3')\n",
    "X_test = hog_complete3.drop(['ClassId','ImageId'], axis =1)\n",
    "y_test = hog_complete3['ClassId']\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55757ac-9a6b-4496-b071-e06e022260a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_accuracy = []\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3,algorithm='brute')\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "test_accuracy = classifier.score((X_test_scaled), y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7a6b2-1115-49b7-ab8c-aa1eca30e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be09da-b323-4637-9376-83b23e9cf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d821963a-fb35-41f2-abe6-27ca6733b741",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Use augmented hog pictures for Training and test (split data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dbb655-47e6-4679-9790-cee631f56801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hog_augmented_complete2 = hog_augmented_complete.query('ClassId != 3') \n",
    "X = hog_augmented_complete.drop(['ClassId','ImageId'], axis =1)\n",
    "y = hog_augmented_complete['ClassId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cde0fd-35c9-485e-a319-77e26689267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y, random_state = 42)\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301417f8-5e34-4343-9b6d-67899697cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3,algorithm='brute')\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "test_accuracy = classifier.score((X_test_scaled), y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3a3bc-71c8-4657-899e-82c8bc244ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d878c-e942-46c0-b835-df355d896d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd7bcd-a59f-4a4d-a954-e07515ca0da3",
   "metadata": {},
   "source": [
    "### Use augmented hog pictures for Training and test (split data) with Blur!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932be05d-6645-47f6-ae09-1c5c0728b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented pictures are based on single defect pictures of classes 1-4\n",
    "hog_augmented_blur = pd.read_csv('data/train_HOG_augmented_blur.csv')\n",
    "hog_augmented_blur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933b1f7-5db6-4bc4-a546-98cc99cf3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_augmented_blur_complete = hog_augmented_blur.merge(df2[['ClassId','ImageId']], on = 'ImageId')\n",
    "hog_augmented_blur_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66572b-61de-4636-8d8c-772219321600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hog_augmented_blur_complete2 = hog_augmented_blur_complete.query('ClassId != 3') \n",
    "X = hog_augmented_blur_complete.drop(['ClassId','ImageId'], axis =1)\n",
    "y = hog_augmented_blur_complete['ClassId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53477851-44f7-4c92-a863-de710f0d69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y, random_state = 42)\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5726f3a-5ff6-49c9-b742-4b6428e5ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3,algorithm='brute')\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "test_accuracy = classifier.score((X_test_scaled), y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186feb46-25e4-48dd-8e38-be9252e4e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45cb23-7e4c-47bb-848f-e51593a292cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257ea1b-a78c-463b-8b67-0432f37fd6ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## SURF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a808c49-41ec-406c-953e-8ede71066488",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = pd.read_csv('data/train_surf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a7b0e-5068-4600-bf6d-35cbd7a2ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.isolate_single_defects(surf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60e234-e7b1-4647-9694-fd70dd282103",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_complete = surf.merge(df[['ClassId','ImageId']], on = 'ImageId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8a4fc-d725-435d-88c5-d1c42f39f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns and split surf_complete into X and y\n",
    "X_surf = surf_complete.drop(['ClassId','ImageId','keypoints'], axis =1)\n",
    "y_surf = surf_complete['ClassId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7bf5ee-0074-4ea2-a4b9-3e6b523ca826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split without oversampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_surf, y_surf, test_size=0.2, \n",
    "                                                    stratify=y_surf, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c526be-b4d4-425e-96f8-e84672523379",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Without Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1500c6f-7048-4759-9323-1e7c1bfead56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3, algorithm='brute')\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "test_accuracy = classifier.score((X_test_scaled), y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbdb18-817e-4466-9011-ca6e859ea7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99703733-714f-4efb-ac5c-cd6bde67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1eb0e1-0aaf-4e09-abe2-b764661eec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out several misclassified images\n",
    "surf_hog_analysis.print_false_classifications(df, surf_complete, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa3077-2e5f-4f93-988e-69a863a57321",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25749df-3181-42e8-a429-72ebb55b715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_sros, y_sros = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7d6c5-c4b6-4ee6-a407-7f2f4fb9741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_sros)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3, algorithm='brute')\n",
    "classifier.fit(X_train_scaled, y_sros)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "test_accuracy = classifier.score((X_test_scaled), y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e40bb1-28e7-4872-91db-711ffa2801ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f4b5c-9200-47a6-a201-b063b6bd7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb7af3-4f0b-4dba-94f6-06ba04054942",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf9169-ba00-4bfa-81a1-b3679eb065bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling with SMOTE\n",
    "X_train_smo, y_train_smo = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1a6f5-d475-4059-a303-c2e7d5ec822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_smo)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=3, algorithm='brute')\n",
    "classifier.fit(X_train_scaled, y_train_smo)\n",
    "\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "test_accuracy = classifier.score((X_test_scaled), y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33014ab-e8c0-40fb-b2b9-694abda8c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860fd595-2651-4601-84a1-77f0e8e5b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03241051-681b-4ca7-aac5-8a302d774f2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6af95-6023-49c3-927d-1e012f0f3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(kernel='rbf', gamma=0.001, C = 100)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa2bee-06e6-45ec-8964-c801319c0460",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "test_accuracy = classifier.score((X_test_scaled), y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eec2b4-fb3e-452e-8808-3c840905fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443a667-5133-44ac-b627-f43444a6ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f313eb5-7a79-454c-9710-5a054338308d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f44386-7852-4356-9438-ef6708db849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_sros, y_sros = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58929d0-701c-45e4-aec4-a0669c281b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_sros)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm_model.fit(X_train_scaled, y_sros)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "test_accuracy = classifier.score((X_test_scaled), y_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556ce22-a9c8-46a2-ba66-c3977a8af781",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, y_pred), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b8345-52b7-45fe-9276-e49a06a06902",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c48e4-a0dd-481a-a36d-ab2ca4c3828b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa6100d-289c-4da0-a717-80817d3b1c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2cfde1-8168-4cb9-8a1f-0f7e0ce1f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'kernel': ['rbf'], \n",
    "               'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "               'C': [1, 10, 100, 1000]},\n",
    "              {'kernel': ['linear'], \n",
    "               'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, verbose=True, n_jobs=-1)\n",
    "\n",
    "result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84718a-64b1-4d13-8581-685d14909f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best parameters \n",
    "print('Best Parameters:', result.best_params_)\n",
    "\n",
    "# Print best score\n",
    "print('Best Score:', result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257e53c-11b3-4145-859c-85f5e3be8d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89780984-8bb7-47bf-95a5-6171b28fb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_complete.groupby(['ClassId']).mean().NumberKP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98946a1b-ad21-443c-b284-b05c82c19101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
