{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7109cdf0-a06f-473b-87e1-8ae63c57ab04",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/hog-histogram-of-oriented-gradients-67ecd887675f\n",
    "\n",
    "https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html\n",
    "\n",
    "https://www.thepythoncode.com/article/hog-feature-extraction-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8fd807-1b3d-4615-9f3b-cf4e10e21364",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f041d-3702-4658-965e-3772f05dad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage.transform import resize\n",
    "import math\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import data, exposure\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d71820-cc46-49e7-8dae-879e6e9bd1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e511f-6f1f-4f2f-8f75-29edfa6f3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = io.imread(\"data/train_images/000418bfc.jpg\")\n",
    "image = io.imread(\"data/train_images/0030401a5.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013786ec-ba3d-461e-8d3e-9157f9b93327",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddded198-8eef-432b-b454-d2d5082a3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.xlim(0,1600)\n",
    "plt.ylim(0,256)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e88c977-da10-4d9b-9446-9e8d1b154a76",
   "metadata": {},
   "source": [
    "The hog() function takes 6 parameters as input:\n",
    "\n",
    "image: The target image you want to apply HOG feature extraction.\n",
    "\n",
    "orientations: Number of bins in the histogram we want to create, the original research paper used 9 bins so we will pass 9 as orientations.\n",
    "\n",
    "pixels_per_cell: Determines the size of the cell, as we mentioned earlier, it is 8x8.\n",
    "\n",
    "cells_per_block: Number of cells per block, will be 2x2 as mentioned previously. ==> used for normalisation (16*16)\n",
    "\n",
    "visualize: A boolean whether to return the image of the HOG, we set it to True so we can show the image.\n",
    "\n",
    "multichannel: We set it to True to tell the function that the last dimension is considered as a color channel, instead of spatial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371cda3-5656-448f-9e00-94826a800ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without resized picture\n",
    "\n",
    "fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(2, 2), visualize=True, channel_axis=-1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(32, 16), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(image, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "\n",
    "# Rescale histogram for better display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ffaf41-ae9f-49c9-a4a9-00bf038684cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img = resize(image, (64,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f45e2f-fae7-4a3b-9ce5-2be4cb86b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with resized picture\n",
    "\n",
    "fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(2, 2), visualize=True, channel_axis=-1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(32, 16), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(resized_img, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "\n",
    "# Rescale histogram for better display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5cc218-24aa-4c3d-ab77-23326e2788d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fd is Feature Matrix\n",
    "fd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ed0a2-b937-46ea-a79d-f58f8463f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13768e6c-525f-4c3f-bdc6-4ca75872a1cd",
   "metadata": {},
   "source": [
    "https://programmerwiki.com/article/9173629512/\n",
    "\n",
    "SCHRITT 1: VERARBEITEN SIE DIE DATEN VOR (64X128)\n",
    "\n",
    "Wir müssen das Bild vorverarbeiten und das Seitenverhältnis auf 1: 2 reduzieren. Die Bildgröße beträgt vorzugsweise 64 x 128. Dies liegt daran, dass wir das Bild in 8 teilen8 und 1616 kleine Blöcke zum Extrahieren von Features. Tatsächlich ist dies genau der Wert, der im Originalpapier verwendet wird.\n",
    "\n",
    "SCHRITT 2: BERECHNEN SIE DEN GRADIENTEN (X- UND Y-RICHTUNG)\n",
    "\n",
    "Um nun den Gradienten in x-Richtung zu bestimmen, müssen wir den linken Wert vom rechten Pixelwert subtrahieren. Um den Gradienten in y-Richtung zu berechnen, subtrahieren wir den Pixelwert unten vom Pixelwert des ausgewählten Pixels.\n",
    "Dieser Prozess liefert zwei neue Matrizen, von denen eine den Gradienten in x-Richtung und die andere den Gradienten in y-Richtung speichert.Wir haben die Gradienten in x- und y-Richtung getrennt berechnet. Wiederholen Sie den gleichen Vorgang für alle Pixel im Bild.\n",
    "\n",
    "SCHRITT 3: BERECHNEN SIE DIE AMPLITUDE UND RICHTUNG\n",
    "\n",
    "Anhand des Gradienten, den wir im letzten Schritt berechnet haben, bestimmen wir nun die Größe und Richtung jedes Pixelwerts. Für diesen Schritt verwenden wir den Satz von Pythagoras um die Gesamtgradientengröße zu berechnen.\n",
    "Berechnen Sie als Nächstes die Richtung desselben Pixels. Wir wissen, dass wir den Winkel als tan schreiben können.\n",
    "Nun haben wir für jeden Pixelwert den Gesamtgradienten (Größe) und die Richtung. Wir müssen diese Gradienten und Richtungen verwenden, um ein Histogramm zu erstellen.\n",
    "\n",
    "SCHRITT 4: BERECHNEN SIE DAS HISTOGRAMM DES GRADIENTEN IN DER 8 × 8-EINHEIT (9 × 1)\n",
    "\n",
    "x-Achse: Anzahl der gewählten Bins (beziehen sich auf Winkel); Anzahl entspricht Parameter: \"Orientations\"\n",
    "y-Achse: Hier wird Größe des Pixelwertes (Amplitude) anteilig auf die jeweils zum Winkel benachbarten bins eingetragen. Bei 9 bins sind Abstände der bins =20. Wenn Winkel bspw. 36 dann werden (40-36)/20= 4/20 * Amplitudenwert auf bin mit Wert beginnend ab 40 eingetragen und (36-20)/20=16/20 * Amplitudenwert auf bin mit Wert ab 20.\n",
    "\n",
    "SCHRITT 4: BERECHNEN SIE DAS HISTOGRAMM DES GRADIENTEN IN DER 8 × 8-EINHEIT (9 × 1)\n",
    "\n",
    "Das im HOG-Feature-Deskriptor erstellte Histogramm wird nicht für das gesamte Bild generiert. Das Bild wird in 8 × 8 Zellen unterteilt und das Histogramm des Richtungsgradienten jeder Zelle berechnet.\n",
    "Auf diese Weise erhalten wir kleine Blockmerkmale (oder Histogramme), die das gesamte Bild darstellen. Wir können diesen Wert natürlich von 8 x 8 auf 16 x 16 oder 32 x 32 ändern.\n",
    "Wenn wir das Bild in 8 × 8-Zellen teilen und ein Histogramm erstellen, generieren wir die Matrix mit der im vorherigen Abschnitt beschriebenen Methode 4 und erhalten für jede Zelle eine 9 x 1-Matrix.\n",
    "\n",
    "SCHRITT 5: NORMALISIEREN SIE DEN GRADIENTEN IN DER 16 × 16-EINHEIT (36 × 1).\n",
    "\n",
    "Obwohl wir HOG-Funktionen für die 8 × 8-Einheiten des Bildes erstellt haben, ist der Gradient des Bildes sehr empfindlich für die Gesamtbeleuchtung. Dies bedeutet, dass für ein bestimmtes Bild einige Teile des Bildes im Vergleich zu anderen Teilen sehr hell sind.\n",
    "Wir können diese Änderung der Beleuchtung jedoch reduzieren, indem wir 16 × 16 Blöcke verwenden, um den Gradienten zu normalisieren.\n",
    "Hier kombinieren wir vier 8 × 8-Einheiten, um einen 16 × 16-Block zu erstellen. Und wir wissen bereits, dass jede 8 × 8-Zelle eine 9 × 1-Matrix für das Histogramm hat. Daher haben wir vier 9 × 1-Matrizen oder eine 36 × 1-Matrix. Um die Matrix zu normalisieren, teilen wir jeden dieser Werte durch die Quadratwurzel der Summe der Quadrate der Werte. Mathematisch für einen gegebenen Vektor V.\n",
    "\n",
    "SCHRITT 6: MERKMALE DES GESAMTEN BILDES\n",
    "\n",
    "Wir werden 105 (7 × 15) Blöcke von 16 × 16 haben. Jeder dieser 105 Blöcke hat einen 36 × 1-Vektor als Merkmal. Daher betragen die Gesamtmerkmale des Bildes 105 × 36 × 1 = 3780 Merkmale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25effb-0fba-4c7b-8a7d-542a72e46864",
   "metadata": {},
   "source": [
    "https://medium.com/swlh/histogram-of-oriented-gradients-hog-for-multiclass-image-classification-and-image-recommendation-cf0ea2caaae8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07360148-dcac-4b8f-8859-ffabb8f16aca",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/anirbanmalick/image-classification-using-hog-knn-98-acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f863e1c-1070-4019-88b1-bea7deeb8f54",
   "metadata": {},
   "source": [
    "## Create HoG for all images in train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248afca-df75-468b-8544-776d3b5448d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current working directory\n",
    "cwd = pathlib.Path.cwd()\n",
    "train_data_dir = cwd.joinpath('data', 'train_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb8c9c-10d8-400e-9570-6ce7336244ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = list(train_data_dir.glob('*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97507406-1b26-4961-80e2-206fa8b66848",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_images = []\n",
    "hog_features = []\n",
    "Image_Ids = []\n",
    "for image in train_images:\n",
    "    Image_Ids.append(image.name)\n",
    "    image = io.imread(\"data/train_images/\"+image.name)\n",
    "    resized_img = resize(image, (64,128))\n",
    "#    blur = cv.GaussianBlur(image,(5,5),0)\n",
    "    fd,hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8,8),cells_per_block=(2,2),visualize=True,channel_axis=-1)\n",
    "    hog_images.append(hog_image)\n",
    "    hog_features.append(fd)\n",
    "  \n",
    "hog_features = np.array(hog_features)\n",
    "\n",
    "hog_features.shape\n",
    "\n",
    "\n",
    "#,block_norm= 'L2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710c6f2-3604-4da5-bed4-173b936ac444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for img in hog_images[:20]:\n",
    " #   plt.imshow(img)\n",
    " #   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a56077-82b5-4ef7-b0eb-25c75a291e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features= pd.DataFrame(hog_features)\n",
    "hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8b3b4-54e4-473f-a31e-d7ec44ba0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Ids= pd.DataFrame(Image_Ids)\n",
    "Image_Ids.rename(columns={0: 'ImageId'}, inplace=True)\n",
    "Image_Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f83c2e0-959a-4af8-8e21-b84401c89561",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_complete = pd.concat([hog_features, Image_Ids], axis=1, ignore_index=False)\n",
    "hog_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b690ead-a190-4ec0-a0de-dad6ca94465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_complete.to_csv('data/train_HOG.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a534a7d4-be0b-45a3-93c2-68ad93177432",
   "metadata": {},
   "source": [
    "## Create HoG for all images in train_single_defects_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c661f-88c0-4ca3-87d7-02a06a93a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current working directory\n",
    "cwd = pathlib.Path.cwd()\n",
    "train_data_dir2 = cwd.joinpath('data', 'augmentations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8722a-e88b-4e04-9809-05c81932ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images2 = list(train_data_dir2.glob('*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0d8ed-a27f-4189-8f45-4bcdb913a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_images_augmented = []\n",
    "hog_features_augmented = []\n",
    "Image_Ids2 = []\n",
    "for image in train_images2:\n",
    "    Image_Ids2.append(image.name)\n",
    "    image = io.imread(\"data/augmentations/\"+image.name)\n",
    "    resized_img = resize(image, (64,128))\n",
    "#    blur = cv.GaussianBlur(image,(5,5),0)\n",
    "    fd2,hog_image_augmented = hog(resized_img, orientations=9, pixels_per_cell=(8,8),cells_per_block=(2,2),visualize=True,channel_axis=-1)\n",
    "    hog_images_augmented.append(hog_image_augmented)\n",
    "    hog_features_augmented.append(fd2)\n",
    "  \n",
    "hog_features_augmented = np.array(hog_features_augmented)\n",
    "\n",
    "hog_features_augmented.shape\n",
    "\n",
    "\n",
    "#,block_norm= 'L2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb8978-4887-4fb3-8df8-dceecd2fa95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features_augmented= pd.DataFrame(hog_features_augmented)\n",
    "hog_features_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87620159-c3ca-4c64-93d2-67c1018a3890",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Ids2= pd.DataFrame(Image_Ids2)\n",
    "Image_Ids2.rename(columns={0: 'ImageId'}, inplace=True)\n",
    "Image_Ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3df18-0484-4f05-98d5-59d922f14535",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_complete_augmented = pd.concat([hog_features_augmented, Image_Ids2], axis=1, ignore_index=False)\n",
    "hog_complete_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb5827c-cdeb-4e12-beb9-9e70ec024064",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_complete_augmented.to_csv('data/train_HOG_augmented.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae576f-ecd6-4d1c-8107-586928e0c930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
