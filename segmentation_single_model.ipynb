{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caf4fedd-f5a9-4c50-bc4b-2fce228b533c",
   "metadata": {},
   "source": [
    "**Ressources**\n",
    "\n",
    "- [Convert Pandas DF into TF Dataset](https://medium.com/when-i-work-data/converting-a-pandas-dataframe-into-a-tensorflow-dataset-752f3783c168)\n",
    "- [Albumentations Doku](https://albumentations.ai/docs/getting_started/mask_augmentation/)\n",
    "- \n",
    "\n",
    "**TensorFlow / Keras**\n",
    "- [Load and preprocess Images](https://www.tensorflow.org/tutorials/load_data/images)\n",
    "- [TF Data Set from Pandas](https://www.tensorflow.org/tutorials/load_data/pandas_dataframe)\n",
    "- [Keras Preprocessing](https://www.tensorflow.org/guide/keras/preprocessing_layers)\n",
    "- [Image segmentation](https://www.tensorflow.org/tutorials/images/segmentation)\n",
    "- [Keras Directory Iterator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f140a-fae1-4505-9113-d140a685f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8452cc-e6a0-4750-ab55-f8e32cc6f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U albumentations --no-binary qudida,albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68476286-c10d-40b8-baef-9d0e166e26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove file directory for changed test run\n",
    "!rm -r data/segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c18924-cb8a-491e-ad00-9151d97fbd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import segmentation_models as sm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import data_preparation_cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c79d8-f100-4101-87c3-061b0ec4491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "DIMENSION = (256, 1600)\n",
    "classId_toRun = 2\n",
    "SEED = 42\n",
    "#Resizing images is optional, CNNs are ok with large images\n",
    "SIZE_X = 128 #Resize images (height  = Y, width = X)\n",
    "SIZE_Y = 512\n",
    "\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.005\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "IMAGES_PER_CLASS = 1000\n",
    "BACKBONE = 'efficientnetb5'\n",
    "SKIP_CONNECTIONS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a772fa-29bb-4d03-8f1f-e136ca57f908",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a0b73-172e-47e7-b54d-3b2dc106c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_complete.csv')\n",
    "\n",
    "# create data frame for defective pictures with added `Mask`\n",
    "defects = df.query('Defect == 1')\n",
    "defects.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd00a65-ef12-4367-91cc-d3f1ba2891c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Preparation for CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593de8c-17a7-4fd7-ac95-c782477147fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create images and masks and their respective augmentations for all 4 defect classes\n",
    "\n",
    "\"\"\"run time: ~ 4:15 \"\"\"\n",
    "\n",
    "# remove file directory for changed test run\n",
    "!rm -r data/segmentation\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "print('Starting data preparations')\n",
    "print('-----'*10)\n",
    "\n",
    "for i in range(4):\n",
    "    print()\n",
    "    data_preparation_cnn.prepare_data_for_class_id(df=defects, \n",
    "                                                   image_dimension=DIMENSION, \n",
    "                                                   seed=SEED, \n",
    "                                                   class_id=i+1, \n",
    "                                                   inverse_masks=False,\n",
    "                                                   num_augmentations = IMAGES_PER_CLASS\n",
    "                                                  )\n",
    "    print()\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print('-----'*10)\n",
    "print('total time for preparations:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371d48e-4ed0-4fbc-a01c-8d6a46d65c57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### CNN-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30810f8a-05d3-4826-9071-f1f89757d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "from modeling.config_CNN_single_class import EXPERIMENT_NAME\n",
    "TRACKING_URI = open(\".mlflow_uri\").read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f5b544-9b27-461a-a9b0-99d52eea76e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run()\n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7a282-cc55-4fca-83d3-57ab11c596b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = sm.get_preprocessing('efficientnetb5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0689e-4116-42d6-ad95-6d33da505188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load images and masks as input for model\n",
    "train_images, train_masks = data_preparation_cnn.get_resized_image_and_mask_lists(class_id=classId_toRun, \n",
    "                                                                                  size_x=SIZE_X, \n",
    "                                                                                  size_y=SIZE_Y)\n",
    "print(train_images.shape)\n",
    "print(train_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca4d3b-8c5f-48fa-8086-853c8dd2393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use customary x_train and y_train variables\n",
    "X = train_images\n",
    "Y = train_masks\n",
    "print(X.shape, Y.shape)\n",
    "Y = np.expand_dims(Y, axis=3) #May not be necessary.. leftover from previous code \n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2b3e3-27d4-4c0b-bd25-0df094dc6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(class_id, size_x, size_y):\n",
    "    images = []\n",
    "    path_suffix = 'c' + str(class_id) + '/'\n",
    "\n",
    "    for directory_path in glob.glob('data/segmentation/test/' + path_suffix):\n",
    "        for img_path in sorted(glob.glob(os.path.join(directory_path, \"*.jpg\"))):\n",
    "            #print(img_path)\n",
    "            #break\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "            img = cv2.resize(img, (size_y, size_x))\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            images.append(img)\n",
    "            #train_labels.append(label)\n",
    "    #Convert list to array for machine learning processing        \n",
    "    images = np.array(images)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b14557-c749-4c43-989a-85495e10fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(class_id, size_x, size_y):\n",
    "    images = []\n",
    "    path_suffix = 'c' + str(class_id) + '/'\n",
    "\n",
    "    for directory_path in glob.glob('data/segmentation/test_mask/' + path_suffix):\n",
    "        for img_path in sorted(glob.glob(os.path.join(directory_path, \"*.png\"))): #.png\n",
    "            #print(img_path)\n",
    "            #break\n",
    "            img = cv2.imread(img_path, 0)       #cv2.IMREAD_GRAYSCALE\n",
    "            img = cv2.resize(img, (size_y, size_x))\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            images.append(img)\n",
    "            #train_labels.append(label)\n",
    "    #Convert list to array for machine learning processing        \n",
    "    images = np.array(images)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe629d-c0dd-4b73-9c36-888b0b79eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = get_images(class_id=classId_toRun, size_x=SIZE_X, size_y=SIZE_Y)\n",
    "y_val = get_masks(class_id=classId_toRun, size_x=SIZE_X, size_y=SIZE_Y)\n",
    "y_val = np.expand_dims(y_val, axis=3) #May not be necessary.. leftover from previous code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ac374-10ca-4ab2-b453-bc2aa0e3c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess input variables\n",
    "x_train = preprocess_input(X)\n",
    "y_train = Y\n",
    "x_val = preprocess_input(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974688fd-90ad-4a68-a319-e63bb702f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m Calcuation Dice Coeffcient and Dice Loss\n",
    "#https://dipanshurana.medium.com/steel-defect-detection-image-segmentation-using-keras-and-tensorflow-6118bc586ad2\n",
    "def dice_coef(y_true,y_pred):\n",
    "    y_true_f = tf.reshape(tf.dtypes.cast(y_true, tf.float32),[-1])\n",
    "    y_pred_f = tf.reshape(tf.dtypes.cast(y_pred, tf.float32),[-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1.) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + 1.)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    return (1-dice_coef(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875cb9fe-3a11-465b-a129-d67c755c5766",
   "metadata": {},
   "source": [
    "#### Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e52ae-4b8d-4ce9-86ce-81248f8849c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.set_framework('tf.keras')\n",
    "\n",
    "sm.framework()\n",
    "# define model\n",
    "#model = sm.Unet()#BACKBONE, encoder_weights='imagenet')\n",
    "\n",
    "model = sm.Unet(BACKBONE,\n",
    "                input_shape=(SIZE_X,SIZE_Y,3),\n",
    "                classes=1,\n",
    "                activation='sigmoid',\n",
    "                encoder_weights='imagenet',\n",
    "                encoder_freeze=True \n",
    "               )\n",
    "model.compile(optimizer=OPTIMIZER, loss=dice_loss, metrics=['accuracy',dice_coef]) \n",
    "\n",
    "\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c50851-a5bf-4997-bdbe-34b24f838c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x_train, \n",
    "                  y_train,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=EPOCHS,\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_val, y_val)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69cbb6a-5206-4fa0-ae16-3972dd246b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coef_value_train = history.history['dice_coef'][-1]\n",
    "dice_coef_value_val = history.history['val_dice_coef'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3501e56-bc93-438f-9ef8-86d36e846433",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['dice_coef'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9463c9d-0e75-4caa-a61a-3e6644df7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'defect_class':classId_toRun,\n",
    "    'images_per_class': IMAGES_PER_CLASS,\n",
    "    'backbone_name': BACKBONE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"size_x\": SIZE_X,\n",
    "    \"size_y\": SIZE_Y,\n",
    "    \"seed\": SEED,\n",
    "    \"optimizer\": OPTIMIZER,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'scip_connections': SKIP_CONNECTIONS\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f03b34-fd26-421b-9dab-8bc3cee21411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging params to mlflow\n",
    "mlflow.log_params(params)\n",
    "#setting tags\n",
    "mlflow.set_tag(\"running_from_jupyter\", \"True\")\n",
    "#logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"DICE\", dice_coef_value_train)\n",
    "mlflow.log_metric(\"validation-\" + \"DICE\", dice_coef_value_val)\n",
    "# logging the model to mlflow will not work without a AWS Connection setup.. too complex for now\n",
    "# but possible if running mlflow locally\n",
    "# mlflow.log_artifact(\"../models\")\n",
    "# mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e9fdb-0725-479d-bdff-f578b0837e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model if desired\n",
    "model.save('test' + str(classId_toRun)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8baf92d-2bd4-4004-8e9e-5f17a9356c24",
   "metadata": {},
   "source": [
    "#### Evaluation of the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c4b034-44c6-491b-a54c-34c4c263ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = model.evaluate(x_val, y_val)\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9b1c5-95d8-4388-86f6-057d9b0786ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb96a94-bee2-43a9-8ae5-6d8667443c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history\n",
    "acc = history.history['dice_coef']\n",
    "val_acc = history.history['val_dice_coef']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, acc, 'y', label='Training dice-coef')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation dice-coef')\n",
    "plt.title('Training and validation Dice-Coefficient')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('dice-coef')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b96ec-2881-43e6-b52c-aba5d999425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_img = get_images(classId_toRun,SIZE_X,SIZE_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c38533-2b45-4f81-a1dd-1ce54499cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7512693a-a2f4-4cd9-86fa-1f812169617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure as subplots\n",
    "i=31\n",
    "\n",
    "fig, ax = plt.subplots(4, 1, constrained_layout=True, figsize=(14, 14))\n",
    "# Subplot 1\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.imshow(real_img[i],interpolation='none')\n",
    "plt.xlim(0,SIZE_Y)\n",
    "plt.ylim(0,SIZE_X)\n",
    "ax[0].set_title('Original Image Nr. ' +str(i), fontsize= 14)\n",
    "\n",
    "\n",
    "# Subplot 2\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.imshow(y_val[i],interpolation='none')\n",
    "plt.xlim(0,SIZE_Y) \n",
    "plt.ylim(0,SIZE_X)\n",
    "ax[1].set_title('Original-Mask Imgage Nr. ' +str(i), fontsize= 14)\n",
    "\n",
    "# Subplot 3\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.imshow(prediction[i],interpolation='none')\n",
    "plt.xlim(0,SIZE_Y) \n",
    "plt.ylim(0,SIZE_X)\n",
    "ax[2].set_title('Predicted-Mask Imgage Nr. ' +str(i), fontsize= 14)\n",
    "\n",
    "# Subplot 4\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.imshow(np.round(prediction[i]),interpolation='none')\n",
    "plt.xlim(0,SIZE_Y) \n",
    "plt.ylim(0,SIZE_X)\n",
    "ax[3].set_title('Binary Predicted-Mask Imgage Nr. ' +str(i), fontsize= 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255be1f6-b206-4f73-8e4c-6cceb42f047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704ab84-e20f-49f8-9f67-5fb65a54f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(x_val, y_val, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b57de0-ce81-47f8-ac0c-7663588153bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View and Save segmented image\n",
    "prediction_image = prediction.reshape(mask.shape)\n",
    "plt.imshow(prediction_image, cmap='gray')\n",
    "# plt.imsave('data/segmentation/test0_segmented.jpg', prediction_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8be4f-fe39-456f-be45-d5df85170dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/segmentation/test_mask/c1/mask_04e23e414.jpg'\n",
    "test_mask = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "test_mask = cv2.resize(test_mask, (SIZE_Y, SIZE_X))\n",
    "plt.imshow(test_mask, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
