{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70abb6d9-8d83-4a33-a8a1-e087bc0fa32e",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2021/06/k-means-clustering-and-transfer-learning-for-image-classification/\n",
    "\n",
    "https://medium.com/@joel_34096/k-means-clustering-for-image-classification-a648f28bdc47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ea207-f204-4ca1-ad6e-2dd1da3fd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.cluster import  KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "from skimage import io\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0df2b0-9d06-4b91-8a03-496334b10b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77545c-0516-4163-9703-5b3b40fb622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the complete dataset (including class 0)\n",
    "df = pd.read_csv('data/train_complete.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867492a-d1a5-4ff4-ab34-6f6dad453ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train dataset without class 0\n",
    "df2 = pd.read_csv('data/train.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8063def-a8ae-42a2-955e-9c826b375d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.isolate_single_defects(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c314d5-cd7f-46ec-aed6-910124418e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677d110-eeee-4710-8767-583c0bdd9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate only images that have 0 or 1 defect\n",
    "util.isolate_single_defects(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14a7a9-d382-4380-8aa7-066c81fb8235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate class 0 images in dataset\n",
    "df = df.query('ClassId!=0')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb64feb-f621-4764-a9c5-0423b883d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe all images with single defects\n",
    "path = pathlib.Path.cwd()\n",
    "try:\n",
    "    os.mkdir(path.joinpath('data','single_defect_train_images'))\n",
    "except:\n",
    "    print('Folder already exists.')\n",
    "    # von Michael kopiert fÃ¼r Ordnererstellung basierend auf x_train\n",
    "    for i in range(len(df)):\n",
    "        origin_train_path = path.joinpath('data', 'train_images')\n",
    "        source_file = df.iloc[i,1]\n",
    "        target_directory = path.joinpath('data', 'single_defect_train_images')\n",
    "        shutil.copy2(origin_train_path.joinpath(source_file) , target_directory.joinpath(source_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357e4fc-1633-4ce0-855c-f170e91bf83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd47180-f8c6-4cf4-b4ef-7fa9a764f261",
   "metadata": {},
   "source": [
    "### Preprozessing for single image (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e4efb-59c6-4042-a7b4-71144043205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image (example)\n",
    "images = io.imread('data/single_defect_train_images/0002cc93b.jpg')\n",
    "print('Org image shape --> ',images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ef426-1623-483c-a379-bc6e66e3818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.grid'] = False\n",
    "plt.imshow(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef4b36-8739-4c7c-9e6b-ff8c3b6bd63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59efff7-565a-462a-8ca1-04909fddf126",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b62a85-bace-4fa3-bb81-48c4cb3b1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize images\n",
    "IMG_SIZE = 32\n",
    "image_resized=cv2.resize(images,(IMG_SIZE,IMG_SIZE))\n",
    "print('After resizing shape --> ',image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363de7a-5f01-4432-9094-2c2e7145632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.grid'] = False\n",
    "plt.imshow(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baceb030-4aa6-4684-886d-d259feb983ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(image_resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838fbfd9-d72b-4f03-9328-e37f162be452",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_resized.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff9cfd-c1c5-4b27-acfd-0e2916d509cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input data have to be converted from 3 dimensional format to 1 dimensional format to be fed into the K-Means Clustering algorithm (Reshape images)\n",
    "#image_flat = image_resized.reshape(len(image_resized),-1)\n",
    "image_flat = image_resized.reshape(1, 3*IMG_SIZE*IMG_SIZE)\n",
    "\n",
    "print('After Flattening shape --> ',image_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a577f2-b370-44ad-8a14-a44e9f3865dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6771ef-e898-4075-9661-4faec5dd71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_flat.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a6a62a-537d-4453-a46e-999ceb2bd9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_images =[]\n",
    "\n",
    "IMG_SIZE = 128\n",
    "for image_id in df['ImageId']:\n",
    "    image = io.imread('data/single_defect_train_images/' + image_id)\n",
    "    #resize images\n",
    "    image_resized=cv2.resize(image,(IMG_SIZE,IMG_SIZE))\n",
    "    #The input data have to be converted from 3 dimensional format to 1 dimensional format\n",
    "    image_flat = image_resized.reshape(1, 3*IMG_SIZE*IMG_SIZE)\n",
    "    # Data Normalization\n",
    "    # Conversion to float\n",
    "    image_flat=image_flat.astype('float32')\n",
    "    # Normalization (In the RGB color space the red, green and blue have integer values from 0 to 255)\n",
    "    image_flat = image_flat/255.0\n",
    "    flattened_images.append([image_id,image_flat[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c85933-07e2-4c2c-946e-f39cfc0ba17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_images= pd.DataFrame(flattened_images , columns = ['ImageId', 'flattened_images'])\n",
    "flattened_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b490aa-bc5e-44c1-aac5-ed2ccdddd526",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af20c3f-71ae-4b15-9890-1a78247dc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_flattened_images = pd.DataFrame(flattened_images['flattened_images'].tolist())\n",
    "#split_flattened_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fcaae9-4853-4db1-8826-025e98068996",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_images = pd.concat([flattened_images, split_flattened_images], axis=1)\n",
    "#flattened_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fdecde-e60c-4984-a2d9-913707d30f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_images_X=flattened_images.drop(['ImageId','flattened_images'], axis = 1)\n",
    "#flattened_images_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75bdac2-3290-4e86-be48-e4bb5aad640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TSNE before modeling\n",
    "tsne = TSNE(n_components=2, init='random', random_state=0)\n",
    "digits_proj = tsne.fit_transform(flattened_images_X)\n",
    "# Creating the KMeans model and predict classes (n_clusters =4 ; due to 4 classes)\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "clusters = kmeans.fit_predict(digits_proj)\n",
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9caa7-8c10-4ef3-832b-8202615e1dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#without TSNE\n",
    "#Creating the KMeans model and predict classes (n_clusters =4 ; due to 4 classes)\n",
    "#kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "#clusters = kmeans.fit_predict(flattened_images_X)\n",
    "#kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debba69f-ec73-4d43-a5a1-7c8139c0037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af51275-07c2-40db-ad89-62213b060f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusters= pd.DataFrame(clusters,columns = ['ClassId_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9bdf7-6942-487d-a629-99ddc7787fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aebce3-980c-4c26-a54c-7a975c416b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c54642-0923-41fd-8711-b6a552720e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "clusters.reset_index(drop=True, inplace=True)\n",
    "result = pd.concat([df, clusters], axis=1)\n",
    "result['ClassId_pred'] = result['ClassId_pred'].map({0: 1, 1: 2,2:3, 3:4})\n",
    "#switch labels due to results from confusion matrix\n",
    "#result['ClassId_pred'] = result['ClassId_pred'].map({1: 1, 2: 2, 3:4, 4:3})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739135b2-f85e-4167-ae6f-94b20c7da8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.groupby('ClassId').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a93006-3e8e-4404-bd96-3c84e907ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(result['ClassId'],result['ClassId_pred']))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(result['ClassId'],result['ClassId_pred']), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac9506a-a3c3-478c-9e9b-4ab8821ab4e7",
   "metadata": {},
   "source": [
    "769\n",
    "195\n",
    "4759\n",
    "516\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ca121-0f39-449d-bf1e-377e249cfce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(result['ClassId'],result['ClassId_pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538996cd-d115-49e0-9eea-fadc3c8f1fd4",
   "metadata": {
    "tags": []
   },
   "source": [
    " ####  without TSNE and img_size = 128\n",
    "   \n",
    "           precision    recall  f1-score   support\n",
    "\n",
    "           1       0.06      0.16      0.09       769\n",
    "           2       0.04      0.18      0.06       195\n",
    "           3       0.71      0.39      0.51      4759\n",
    "           4       0.07      0.11      0.09       516\n",
    "\n",
    "    accuracy                           0.34      6239\n",
    "   macro avg       0.22      0.21      0.19      6239\n",
    "weighted avg       0.56      0.34      0.41      6239"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591a028-c9a1-42c6-a175-3bcfc36ff424",
   "metadata": {},
   "source": [
    " #### with TSNE  and img_size = 128  \n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "           1       0.18      0.40      0.25       769\n",
    "           2       0.09      0.38      0.14       195\n",
    "           3       0.68      0.28      0.40      4759\n",
    "           4       0.11      0.37      0.17       516\n",
    "\n",
    "    accuracy                           0.31      6239\n",
    "   macro avg       0.26      0.36      0.24      6239\n",
    "weighted avg       0.55      0.31      0.35      6239"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d1850-8eda-438c-a837-f689ed76df1a",
   "metadata": {},
   "source": [
    "## Clustering with HOG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f26223-83da-4a70-b0ac-0a23e0048f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the HOG feature dataset \n",
    "hog = pd.read_csv('data/train_HOG.csv')\n",
    "hog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94880257-bd19-48c6-a7d3-7d42134cf062",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91249cd-75ce-4c82-943c-ce64f6e2f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate only images that have 0 or 1 defect\n",
    "util.isolate_single_defects(hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1d37f-29ed-4b8e-a653-bb99babc26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b80e5b-7d5f-4c0b-bcdd-2d5d0218031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the complete dataset (including class 0)\n",
    "df2 = pd.read_csv('data/train_complete.csv')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a5fe3-ee61-4def-9c6d-6497d84b0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = hog.merge(df2, on='ImageId')\n",
    "hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279489d0-de29-41c5-a720-677c445362d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate class 0 images in dataset\n",
    "hog = hog.query('ClassId!=0')\n",
    "hog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fec44c-fabb-45ce-ac68-f307c809e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_X=hog.drop(['ImageId','FilePath','ClassId','EncodedPixels','Defect'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c333b197-b8a4-409a-86f5-913b3f69890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Use TSNE before modeling\n",
    "tsne = TSNE(n_components=2, init='random', random_state=0)\n",
    "digits_proj = tsne.fit_transform(hog_X)\n",
    "# Creating the KMeans model and predict classes (n_clusters =4 ; due to 4 classes)\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "clusters = kmeans.fit_predict(digits_proj)\n",
    "kmeans.cluster_centers_.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f20707-cece-469f-b4b7-0169c699af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without TSNE\n",
    "#Creating the KMeans model and predict classes (n_clusters =4 ; due to 4 classes)\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "clusters = kmeans.fit_predict(hog_X)\n",
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753fe79e-0132-4028-9e96-c9d2ad4f1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters= pd.DataFrame(clusters,columns = ['ClassId_pred'])\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948fd872-f2a0-4b08-8440-c10a4459de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog.reset_index(drop=True, inplace=True)\n",
    "clusters.reset_index(drop=True, inplace=True)\n",
    "result = pd.concat([hog, clusters], axis=1)\n",
    "result['ClassId_pred'] = result['ClassId_pred'].map({0: 1, 1: 2,2:3, 3:4})\n",
    "#switch labels due to results from confusion matrix\n",
    "#result['ClassId_pred'] = result['ClassId_pred'].map({1: 1, 2: 2, 3:4, 4:3})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e05247-e718-4982-832f-f1e3a0f99822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(result['ClassId'],result['ClassId_pred']))\n",
    "# Print confusion matrix\n",
    "sns.heatmap(metrics.confusion_matrix(result['ClassId'],result['ClassId_pred']), annot=True, cmap='YlGn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de5e8c-123a-4f47-b11f-55a2c7fba16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(result['ClassId'],result['ClassId_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f46f3-dc9a-4df2-88db-f01d5136287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Create a labels array to match the learned cluster lables with the true labels\n",
    "labels = np.zeros_like(clusters)\n",
    "for i in range(4):\n",
    "    mask = (clusters == i)\n",
    "    labels[mask] = mode(hog.ClassId[mask])[0]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7653cfd-5f77-4778-a750-0900ffb54b91",
   "metadata": {},
   "source": [
    "### HOG without TSNE        \n",
    "        precision    recall  f1-score   support\n",
    "\n",
    "           1       0.12      0.18      0.15       769\n",
    "           2       0.06      0.70      0.10       195\n",
    "           3       0.81      0.27      0.41      4759\n",
    "           4       0.01      0.01      0.01       516\n",
    "\n",
    "    accuracy                           0.25      6239\n",
    "   macro avg       0.25      0.29      0.17      6239\n",
    "weighted avg       0.63      0.25      0.33      6239"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b19528-9a33-4871-8f6f-1610f303b874",
   "metadata": {
    "tags": []
   },
   "source": [
    "   ### HOG with TSNE        \n",
    "        precision    recall  f1-score   support\n",
    "\n",
    "           1       0.12      0.36      0.18       769\n",
    "           2       0.00      0.04      0.01       195\n",
    "           3       0.77      0.18      0.29      4759\n",
    "           4       0.02      0.03      0.02       516\n",
    "\n",
    "    accuracy                           0.18      6239\n",
    "   macro avg       0.23      0.15      0.12      6239\n",
    "weighted avg       0.61      0.18      0.24      6239"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7681e1-f0e7-4988-9714-5bead3678ce2",
   "metadata": {},
   "source": [
    "## Using HOG Image in Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71113cf-6179-4ffc-8a32-8f3bdc2aa098",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread(\"data/train_images/000f6bf48.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd18d6-90ac-4f81-b515-9e49f0a6a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "resized_img = resize(image, (64,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c67f0-eaa4-4cca-a9f3-21a308b2d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resized_img)\n",
    "plt.xlim(0,128)\n",
    "plt.ylim(0,64)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc45a16-87a4-47ee-aa0b-33488ec5ce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(2, 2), visualize=True, channel_axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9ad7c-1e10-4307-a478-9d2016880e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hog_image)\n",
    "plt.xlim(0,128)\n",
    "plt.ylim(0,64)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0532c54-bf67-4196-8d23-6701550e2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_n = hog_image.reshape(hog_image.shape[0]*hog_image.shape[1],1)\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(pic_n)\n",
    "#clusters = kmeans.fit_predict(hog_image)\n",
    "#kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92441e4-87cb-4c42-9dc9-8ef48df2b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic2show = kmeans.cluster_centers_[kmeans.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108f465-037f-4b51-a0e6-a3ab8b65beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_pic = pic2show.reshape(hog_image.shape[0], hog_image.shape[1])\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(cluster_pic);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e88da-4e1e-463d-8a78-9652c12260d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa4915-fee4-4f54-8812-c4edd248251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114ba28-2839-4ef9-9c4c-d5c5c651523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0da0d1-570f-4903-8a09-0c36179f6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import mask_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9913ba-4e76-47c2-9411-17d1ceda1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pic = kmeans.labels_.reshape(hog_image.shape[0], hog_image.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ddf9c8-8975-4702-8abd-803393de838e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca790f2-46ee-4bec-b0a0-45423c84ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a598f70-a169-4a52-9c2f-33d66d46f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DIMENSION = (64,128)\n",
    "encoded_pixels = mask_conversion.encode_pixel(mask_pic, 3)\n",
    "mask_conversion.decode_pixel(DIMENSION,encoded_pixels=encoded_pixels,class_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e555a530-97a0-4fc0-b2d2-5cbb856fecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique values in kmeans labels\n",
    "labels = list(set(kmeans.labels_))\n",
    "\n",
    "for label in labels:\n",
    "    DIMENSION = mask_pic.shape\n",
    "    encoded_pixels=mask_conversion.encode_pixel(mask_pic, label)\n",
    "    \n",
    "    mask = mask_conversion.decode_pixel(DIMENSION,encoded_pixels=encoded_pixels,class_id=1)\n",
    "\n",
    "    plt.figure(figsize=(25, 8))\n",
    "        \n",
    "    ax = plt.subplot(len(labels), 1, label + 1)\n",
    "    #plt.imshow(img)\n",
    "    title = f'Label: {label}'\n",
    "    \n",
    "    plt.title(title, fontsize=16);\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2178b-1fc5-4b78-ba49-2960c59eaf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
