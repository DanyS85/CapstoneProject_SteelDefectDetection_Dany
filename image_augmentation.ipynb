{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c66929e-4da1-4b5f-86ae-22ebabbf054e",
   "metadata": {},
   "source": [
    "**Ressources**:\n",
    "\n",
    "- [TF Tutorial](https://www.tensorflow.org/tutorials/images/data_augmentation)\n",
    "- [Image Augmentation](https://towardsdatascience.com/image-augmentation-for-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085)\n",
    "- [Image Augmentation with Keras in Histogramm Equalization](https://towardsdatascience.com/image-augmentation-for-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe24b1ba-4a0d-4878-98ac-1500b9240a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import util\n",
    "import surf_hog_analysis\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5edc908-423d-4a03-a410-70050259e0c9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea342d82-0bc5-4925-8fd5-81143dc68f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Only execute once to create `.csv` file\"\"\"\n",
    "df = pd.read_csv('data/train_complete.csv')\n",
    "\n",
    "df = util.add_blackness_attributes(df.query('Defect==1'), 'train_images')\n",
    "\n",
    "util.isolate_single_defects(df)\n",
    "\n",
    "df.to_csv('data/train_single_defects_with_blackness.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0559fd-47cf-4c61-bc1c-9cdee8ff59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd = pd.read_csv('data/train_single_defects_with_blackness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e2295-3886-454c-8cb0-f78ac1a936be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sd.copy()\n",
    "y = X.pop('ClassId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e524c-4a7b-4462-aa0c-6d9113a99ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a681050-f305-4756-b037-cf5c764ea58f",
   "metadata": {},
   "source": [
    "Since oversampling is only applied to the training data, we needed to split our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b451eb7-5333-4ff4-be6f-a7167570ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_images = X_train.loc[util.get_indices_for_class_id(y_train, 1)]\n",
    "class2_images = X_train.loc[util.get_indices_for_class_id(y_train, 2)]\n",
    "class3_images = X_train.loc[util.get_indices_for_class_id(y_train, 3)]\n",
    "class4_images = X_train.loc[util.get_indices_for_class_id(y_train, 4)]\n",
    "\n",
    "print(f'There are {len(class1_images)} train images for ClassId 1')\n",
    "print(f'There are {len(class2_images)} train images for ClassId 2')\n",
    "print(f'There are {len(class3_images)} train images for ClassId 3')\n",
    "print(f'There are {len(class4_images)} train images for ClassId 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe271a5-a6fe-45c8-8861-3436019f7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ClassId 2 corresponds to {len(class2_images) / len(X_train)} % of train images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612b6ab-2e67-4f37-9173-9862e88c9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily safe all images from `ClassId` 2\n",
    "path = pathlib.Path.cwd()\n",
    "try:\n",
    "    os.mkdir(path.joinpath('data','oversampling_test'))\n",
    "except:\n",
    "    print('Images already exist.')\n",
    "    \n",
    "# von Michael kopiert fÃ¼r Ordnererstellung basierend auf x_train\n",
    "for i in range(len(class2_images)):\n",
    "    origin_train_path = path.joinpath('data', 'train_images')\n",
    "    source_file = class2_images.iloc[i,1]\n",
    "    target_directory = path.joinpath('data', 'oversampling_test')\n",
    "    shutil.copy2(origin_train_path.joinpath(source_file) , target_directory.joinpath(source_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8208e-67f4-4cf0-95e7-38cb067c5722",
   "metadata": {},
   "source": [
    "After having a look at the images from `ClassId` 2, it becomes clear, that many of them have a high percentage of black pixels, some are entirely black even. It may be useful to delete such images since an augmentation would not really help to strengthen the robustness to identify images of this `ClassId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb37eb-997e-4155-b76b-7ecd9852f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch(df_with_filepath, class_ids, blackness=False, show_keypoints=False, number_images=5):\n",
    "    # create random index for `number_images`\n",
    "    random_index = np.array(np.random.rand(2 * number_images) * len(df_with_filepath.ImageId), dtype='int')\n",
    "    # print(random_index)\n",
    "    # define subplot grid\n",
    "    fig, axes = plt.subplots(number_images, 2, figsize=(18,8))\n",
    "\n",
    "    for i in range(number_images * 2):\n",
    "        # gather required info to retrieve image and label the plots\n",
    "        file_path_to_image = df_with_filepath['FilePath'].iloc[random_index[i]]\n",
    "        class_id = class_ids.iloc[random_index[i]]\n",
    "        image_id = df_with_filepath['ImageId'].iloc[random_index[i]]\n",
    "        if blackness:\n",
    "            blackness = df_with_filepath['PercentageBlack'].iloc[random_index[i]]\n",
    "            # print(df_with_filepath['PercentageBlack'])\n",
    "        if show_keypoints:\n",
    "            keypoints = df_with_filepath['NumberKP'].iloc[random_index[i]]\n",
    "\n",
    "        # read-in the image\n",
    "        img = io.imread(file_path_to_image)\n",
    "        \n",
    "        row = i % number_images\n",
    "        col = int(i // number_images)\n",
    "        ax_ = axes[row][col]\n",
    "        ax_.imshow(img)\n",
    "        #plt.imshow(img)\n",
    "        \n",
    "        title = f'Image ID: {image_id} | ClassId: {class_id}'\n",
    "        if blackness:\n",
    "            title += f' | Percentage Black: {blackness}'\n",
    "        if show_keypoints:\n",
    "            title += f' | Number Keypoints: {keypoints}'\n",
    "        ax_.set_title(title, fontsize=14);\n",
    "        \n",
    "        # adjust distance between subplots\n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=1, \n",
    "                    top=1.2, \n",
    "                    wspace=0.2, \n",
    "                    hspace=0.2)\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb5e64-295e-40cf-8c70-57c370aa8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = y_train[util.get_indices_for_class_id(y_train, 2)]\n",
    "print_batch(class2_images, class_ids, blackness=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758fb2cb-3eb8-45c2-8d01-8747e3fe56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread('data/oversampling_test/b963c168c.jpg')\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d997dd-1069-4def-8525-4c1428f43f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_columns = util.get_black_columns(image)\n",
    "black_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581104d-05fe-4aed-8bd9-d908fec1c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.axvline(x=black_columns)\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f188295-a3ca-41ff-8071-aec0e84ce032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class2_images = util.add_blackness_attributes_for_single_class(class2_images, y_train,'oversampling_test', class_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856289d-5d3b-4bc9-9a67-dab1bc1340a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2_images.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753f7ca-e871-455e-84b0-b8acc5cf72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mostly_black = class2_images.query('PercentageBlack >= 0.5').ImageId.count()\n",
    "print(f'There are {num_mostly_black} pictures (or {num_mostly_black / class2_images.shape[0]} % \\\n",
    "        of total) images that are mostly black (>= 50 %).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8a85b-f9de-4996-a8b4-0480256b15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostly_black = class2_images.query('PercentageBlack >= 0.5')\n",
    "mostly_black.PercentageBlack.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8c78d-e534-45c3-873e-679ecdab5222",
   "metadata": {},
   "source": [
    "It is striking, that `mostly_black` images have at least 72 % blackness on them (up to 94.5 %)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e1e26-4b39-456b-8d68-bb6f620f0123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some images of `mostly_black`\n",
    "class_ids_mb = y_train[util.get_indices_for_class_id(y_train, 2)]\n",
    "print_batch(mostly_black, class_ids_mb, blackness=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6297db-0dd9-43eb-9c1c-06dddd7f6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the distribution of blackness among all `ClassIds`\n",
    "df_sd.groupby('ClassId').PercentageBlack.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b949dc6-a252-4dde-a2ce-1ab3fe7e689d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Augementation trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e06f3-11f3-4601-9bc5-9a1cd38cdaee",
   "metadata": {},
   "source": [
    "[`tf.image`](https://www.tensorflow.org/api_docs/python/tf/image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1523f7b7-5850-474e-9533-a17357fa25ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import albumentations\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "\n",
    "# self-written scripts\n",
    "import sys\n",
    "sys.path.insert(0, 'Python_Scripts')\n",
    "\n",
    "import data_preparation_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75babed1-692d-4b03-9fce-82c4baa1a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder():\n",
    "    # prepare folder structure\n",
    "    try:\n",
    "        path = os.getcwd()\n",
    "        temp_path = path + \"/data/augmentations\"\n",
    "        os.mkdir(temp_path)\n",
    "    except:\n",
    "        print('Folder already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee0083d-60a2-4fc3-ae85-97e97c21adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "augment = A.Compose([\n",
    "    #A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # A.OneOf([\n",
    "    #     A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
    "    #     A.GridDistortion(p=0.5),\n",
    "    #     A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)                  \n",
    "    #     ], p=0.8),\n",
    "    A.CLAHE(p=0.8),\n",
    "    A.RandomBrightnessContrast(p=0.8),    \n",
    "    A.RandomGamma(p=0.8)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9334e17-8d39-452b-a4e4-15f16589a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augement_images(image_ids, num_augmentations, class_id):\n",
    "    print(f'beginning augmentation for ClassId {class_id}...')\n",
    "    start = time.time()\n",
    "    \n",
    "    path = os.getcwd()\n",
    "    #path_suffix = 'c' + str(class_id) + '/'\n",
    "    \n",
    "    target_directory_image = '/data/augmentations/'\n",
    "    \n",
    "    aug_ids = []\n",
    "    class_ids = []\n",
    "    file_paths = []\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    while i <= num_augmentations:\n",
    "        #print(i)\n",
    "        number = random.randint(0, len(image_ids) -1)\n",
    "        image_id = image_ids[number]\n",
    "        #print(image_id, mask_id)\n",
    "        \n",
    "        aug_ids.append('aug_' + str(i) + '_' + image_id)\n",
    "        class_ids.append(class_id)\n",
    "        file_paths.append(path + target_directory_image + image_id)\n",
    "        \n",
    "        original_image = cv2.imread('data/train_images/' + image_id)\n",
    "        #print(original_image)\n",
    "      \n",
    "        augmented = augment(image=original_image)\n",
    "        transformed_image = augmented['image']\n",
    "        #transformed_mask = augmented['mask']\n",
    "        \n",
    "        os.chdir(path + target_directory_image)\n",
    "        written = cv2.imwrite('aug_' + str(i) + '_' + image_id, transformed_image)\n",
    "        #print('image written:',written')\n",
    "\n",
    "        os.chdir(path)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    temp = pd.DataFrame(list(zip(file_paths,aug_ids, class_ids)), columns=['FilePath','ImageId','ClassId'])\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'augmented {num_augmentations} images of ClassId {class_id}')\n",
    "    print('time required for augmentation:', end - start)\n",
    "    print()\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2978101-a844-4924-a748-2dad24a6a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_aug(df):\n",
    "    \n",
    "    make_folder()\n",
    "    \n",
    "    num_images_class_3 = df.groupby('ClassId').count().ImageId[3]\n",
    "    max_images = num_images_class_3\n",
    "\n",
    "    # create empty df\n",
    "    df_aug = pd.DataFrame(columns=['FilePath','ImageId','ClassId'])\n",
    "\n",
    "    for i in [1,2,3,4]:\n",
    "        image_ids = df.query('ClassId == @i').ImageId.values\n",
    "\n",
    "        temp = augement_images(image_ids=image_ids, num_augmentations=max_images, class_id=i)\n",
    "        df_aug=pd.concat([df_aug, temp], axis=0)\n",
    "\n",
    "    return df_aug.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7240b002-bbfa-46b6-9f68-1d5b636a2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/train_single_defects_with_blackness.csv')\n",
    "\n",
    "# df_aug = create_df_aug(df)\n",
    "\n",
    "# df_aug.to_csv('data/train_single_defects_augmented.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb1aa57-2925-4814-867d-c315ea6e3dbf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Augmentation for Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e0889b-4492-4d4e-bd08-d5a2ff273a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd = pd.read_csv('data/train_single_defects_with_blackness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbd1b646-42c5-4d4b-8130-1acaf4d38fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sd.copy()\n",
    "y = X.pop('ClassId')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15a343fc-c6f1-4fe7-9233-f4761498392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame for train and test\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b96660be-da6e-4ebb-9f83-a961acdaf31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning augmentation for ClassId 1...\n",
      "augmented 2866 images of ClassId 1\n",
      "time required for augmentation: 23.72112774848938\n",
      "\n",
      "beginning augmentation for ClassId 2...\n",
      "augmented 2866 images of ClassId 2\n",
      "time required for augmentation: 21.805581092834473\n",
      "\n",
      "beginning augmentation for ClassId 3...\n",
      "augmented 2866 images of ClassId 3\n",
      "time required for augmentation: 24.977601051330566\n",
      "\n",
      "beginning augmentation for ClassId 4...\n",
      "augmented 2866 images of ClassId 4\n",
      "time required for augmentation: 25.065805196762085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Only execute ONCE\"\"\"\n",
    "# apply augmentation to train images\n",
    "df_train_aug = create_df_aug(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb1895e2-dd06-4b01-9faf-5ca0d0a84a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train-test-splits to .csv to feed them into the models\n",
    "df_train_aug.to_csv('data/train_set_augmented.csv', sep=',', index=False)\n",
    "df_test.to_csv('data/test_set_for_augmented.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01b631-d112-4955-b9b2-118f1b9d522b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf3f2e-d57b-476a-b4a8-8c4d3e0551ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_for_class_id(y, class_id):\n",
    "    pos_of_class_id = (y == class_id)\n",
    "    indices = pos_of_class_id[pos_of_class_id].index.values\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8460369-77bc-4604-9454-bf1165e3bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_black_columns(image, threshold=5):\n",
    "    num_columns = 0\n",
    "    \n",
    "    for column in range(image.shape[1]):\n",
    "        color_sum = image[:, column].sum()\n",
    "        \n",
    "        if color_sum <= image.shape[0] * 3 * threshold:\n",
    "            num_columns += 1\n",
    "            \n",
    "    return num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293072b-9e63-4590-8d66-55e5bd4286c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_blackness_attributes(image_df, folder_extension):\n",
    "    \"\"\"returns the `image_df` extended by columns `BlackColumns` and `PercentageBlack`.\n",
    "    \n",
    "    Input parameters:\n",
    "    image_df         - data frame that includes `ImageIds`\n",
    "    folder_extension - the subfolder in 'data/' where pictures are located\n",
    "    \"\"\"\n",
    "    black_columns = []\n",
    "    black_columns_percentage = []\n",
    "\n",
    "    for image_id in image_df.ImageId:\n",
    "        image = io.imread('data/' + folder_extension + '/' + image_id)\n",
    "        black_columns.append(get_black_columns(image))\n",
    "        black_columns_percentage.append(get_black_columns(image) / image.shape[1])\n",
    "    \n",
    "    temp = pd.DataFrame(list(zip(black_columns, black_columns_percentage)), \n",
    "                        columns = ['BlackColumns', 'PercentageBlack'])\n",
    "        \n",
    "    image_df = pd.merge(image_df, temp, left_index=True, right_index=True)\n",
    "\n",
    "    return image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108d830-ec8e-49c4-967a-a52f946b101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate and see the pictures and labels\n",
    "# img_batch, labels = next(it)\n",
    "# image = img_batch[0]\n",
    "# #print(img_batch)\n",
    "# plt.imshow(image)\n",
    "# print(labels[0])\n",
    "# image = image.numpy() \n",
    "# image *= 256\n",
    "# written = cv2.imwrite(cwd.as_posix() + '/image.jpg', image)\n",
    "# print(written)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
